# Pre-Implementation Documentation: E03-F01-T01 - Graph Traverser Service

## Overview

### Problem Context

The Expansion Engine requires efficient graph traversal to support hop-based incremental exploration. Users will expand from selected pins, nets, or cells, requiring the system to quickly identify all connected cells within N hops in either fanin (upstream) or fanout (downstream) direction. This traversal is a foundational capability that must be performant, correct, and architecturally clean.

### Scope

This task implements the core graph traversal logic that powers the expansion feature. It consists of:
1. A domain-layer protocol (`GraphTraverser`) defining the traversal interface
2. An infrastructure-layer implementation using NetworkX (`NetworkXGraphTraverser`)
3. BFS-based traversal algorithms for fanin and fanout directions
4. Edge case handling (power/ground nets, unconnected pins, loops, bidirectional pins)

### Success Criteria

- Traversal correctly identifies all cells within N hops (1-5+)
- Performance targets met: <100ms for 1-hop, <500ms for 5-hop on 100K cell designs
- Clean architecture maintained: domain protocol separate from infrastructure implementation
- All edge cases handled gracefully
- 90%+ test coverage with comprehensive unit and integration tests

## Implementation Approach

### High-Level Strategy

1. **Define Domain Protocol**: Create `GraphTraverser` protocol in domain layer with `get_fanout()` and `get_fanin()` methods
2. **Implement BFS Traversal**: Use breadth-first search (not DFS) to avoid stack overflow and enable hop counting
3. **NetworkX Integration**: Build traverser on NetworkX DiGraph structure already created by E01-F03 (Graph Construction)
4. **Edge Case Handling**: Implement filtering for power/ground nets, handle unconnected pins, loops, and INOUT pins
5. **Performance Optimization**: Cache net connectivity lookups, short-circuit at hop limits, profile with realistic netlists

### Architecture Pattern

Following Clean Architecture/DDD principles:

```
Domain Layer (Protocol)
    ↑
    | depends on
    |
Infrastructure Layer (Implementation)
```

The application layer will depend on `GraphTraverser` protocol, and dependency injection will provide the NetworkX implementation at runtime.

### Algorithm Design

**BFS Fanout Traversal:**
```
1. Start from pin, get connected net
2. Find all load pins on that net
3. For each load pin, add parent cell to result set
4. If hops > 1, add cells to next level queue
5. Process next level, decrement hop counter
6. Repeat until hop counter reaches 0
7. Return accumulated cell set
```

**BFS Fanin Traversal:**
```
1. Start from pin, get connected net
2. Find driver pin on that net
3. Add driver's parent cell to result set
4. If hops > 1, expand from cell's input pins
5. Process recursively until hop counter reaches 0
6. Return accumulated cell set
```

## Key Design Decisions

### Decision 1: BFS vs DFS

**Options:**
- Breadth-first search (BFS)
- Depth-first search (DFS)
- Bidirectional search

**Chosen: BFS**

**Rationale:**
- BFS naturally supports hop-based expansion (each BFS level = 1 hop)
- Avoids deep recursion stack issues in large netlists
- Easier to implement hop limit short-circuiting
- Better locality for cache performance

**Trade-offs:**
- Slightly higher memory usage than DFS
- Need to maintain level queues

### Decision 2: Graph Representation Assumptions

**Assumption:** NetworkX DiGraph structured as:
```python
# Nodes: Cell entities
graph.add_node(cell_id, cell=cell_entity)

# Edges: Connectivity via nets
graph.add_edge(driver_cell_id, load_cell_id,
               net=net_entity,
               driver_pin=driver_pin,
               load_pin=load_pin)
```

**Implications:**
- Direct edge traversal from cell to cell
- Edge attributes store net and pin metadata
- May need to access net connectivity separately for multi-load nets

**Alternative:** Store nets as separate graph structures with pin membership. Rejected due to added complexity.

### Decision 3: Power/Ground Net Filtering

**Problem:** VDD/VSS nets connect to nearly every cell, causing full-design expansion

**Solution:** Filter power/ground nets by:
- Net name pattern matching (`VDD`, `VSS`, `GND`, etc.)
- Net type annotation (if available in CDL)
- Configurable filtering rules

**Implementation:** Add `is_power_ground()` method to `Net` entity in domain model.

### Decision 4: Handling INOUT Pins

**Options:**
1. Treat INOUT as both driver and load
2. Treat INOUT based on context
3. Special bidirectional expansion mode

**Chosen: Option 1 - Both driver and load**

**Rationale:**
- Simplest to implement
- Most conservative (shows all connections)
- User can collapse unwanted expansions

### Decision 5: Caching Strategy

**Decision:** No caching in traverser initially

**Rationale:**
- Expansion state is dynamic (cells added/removed)
- Cache invalidation complexity
- NetworkX already optimized for graph queries
- Can add later if profiling shows benefit

**Future Enhancement:** Consider caching if performance targets not met.

## Dependencies and Integration Points

### Upstream Dependencies

1. **E01-F03 (Graph Construction)** - CRITICAL
   - Provides NetworkX DiGraph structure
   - Graph must be populated before traverser can function
   - Need to verify graph schema matches assumptions

2. **E01 (Data Model)** - CRITICAL
   - `Cell`, `Pin`, `Net` entities
   - `CellId`, `PinId` value objects
   - `PinDirection` enum
   - Domain model must be stable before implementation

### Downstream Dependencies

1. **E03-F01-T02 (Expansion Trigger Handling)** - CONSUMER
   - Will call `get_fanout()` and `get_fanin()`
   - Expects `Set[Cell]` return type
   - Needs performance SLA (<100ms 1-hop)

2. **E03-F01-T03 (Duplicate Prevention)** - CONSUMER
   - Receives traversal results for filtering
   - No direct dependency, but sequential in workflow

### Integration Challenges

**Challenge 1: Graph Schema Validation**
- Risk: NetworkX graph structure differs from assumptions
- Mitigation: Add validation in traverser constructor, write integration test with real graph

**Challenge 2: Pin-to-Net Association**
- Risk: Pin entity may not have direct reference to connected net
- Mitigation: Review domain model, may need to query via graph or design aggregate

**Challenge 3: Multi-Driver Nets**
- Risk: Nets with multiple drivers (tri-state) complicate fanin traversal
- Mitigation: Return all drivers, document behavior, test explicitly

## Testing Strategy

### Unit Tests (Infrastructure Layer)

**Test File:** `tests/unit/infrastructure/graph/test_networkx_graph_traverser.py`

**Test Categories:**

1. **Basic Traversal**
   - 1-hop fanout from output pin
   - 1-hop fanin from input pin
   - N-hop fanout (2, 3, 5 hops)
   - N-hop fanin (2, 3, 5 hops)

2. **Edge Cases**
   - Unconnected pin (returns empty set)
   - Invalid hop count (raises ValueError)
   - None pin (raises ValueError)
   - Power/ground net filtering
   - Combinational loops (cycle detection)
   - INOUT pins (bidirectional)
   - Multi-driver nets

3. **Boundary Conditions**
   - 0 hops (invalid)
   - 1 hop (minimal)
   - 10+ hops (deep traversal)
   - Large fanout (100+ loads on single net)

**Mocking Strategy:** Use synthetic NetworkX graphs with known topology:

```python
def create_test_graph():
    """Create simple chain: A -> B -> C -> D"""
    graph = nx.DiGraph()
    # Add nodes and edges
    return graph
```

### Integration Tests

**Test File:** `tests/integration/infrastructure/graph/test_graph_traversal_integration.py`

**Test Scenarios:**

1. **Simple Chain:** A → B → C → D
   - Verify 1-hop from A returns {B}
   - Verify 2-hop from A returns {B, C}
   - Verify 3-hop from A returns {B, C, D}

2. **Fanout Tree:** A → [B, C, D]
   - Verify 1-hop from A returns {B, C, D}

3. **Fanin Merge:** [A, B, C] → D
   - Verify 1-hop fanin from D returns {A, B, C}

4. **Complex Logic Path:** Realistic 10+ cell path with 5+ hop traversal

**Data:** Use real CDL files from `examples/` directory or create synthetic `.ckt` files

### Performance Tests

**Test File:** `tests/performance/test_traversal_performance.py`

**Benchmarks:**

1. **1-hop fanout on 100K cell design:** <100ms
2. **5-hop fanout on 100K cell design:** <500ms
3. **Memory usage:** Should not grow unboundedly for deep traversals

**Profiling:**
- Use `pytest-benchmark` for timing
- Use `memory_profiler` for memory tracking
- Profile with realistic netlists (generate synthetic if needed)

### Test Data Requirements

**Needed:**
- Small synthetic graphs (5-20 cells) for unit tests
- Medium synthetic graphs (100-1000 cells) for integration tests
- Large synthetic graphs (100K cells) for performance tests
- Real-world CDL samples if available

## Risks and Considerations

### Technical Risks

**Risk 1: Performance Targets Not Met**
- Likelihood: Medium
- Impact: High
- Mitigation: Profile early, optimize hot paths, consider rustworkx if needed
- Contingency: Reduce hop limit, add performance mode with simplified traversal

**Risk 2: NetworkX Graph Schema Mismatch**
- Likelihood: Low
- Impact: High
- Mitigation: Coordinate with E01-F03, validate assumptions in integration test
- Contingency: Adapt traverser to actual schema, may need to modify graph construction

**Risk 3: Combinational Loops**
- Likelihood: Medium (some designs have loops)
- Impact: Medium (infinite traversal)
- Mitigation: Track visited cells, detect cycles, limit iteration count
- Contingency: Document limitation, warn user

### Architectural Risks

**Risk 1: Domain Protocol Too Restrictive**
- Likelihood: Low
- Impact: Medium
- Mitigation: Keep protocol simple, extensible
- Contingency: Add methods to protocol if needed (backward compatible)

**Risk 2: Tight Coupling to NetworkX**
- Likelihood: Low
- Impact: Low (design allows replacement)
- Mitigation: Protocol abstraction isolates dependency
- Contingency: Future migration to rustworkx if needed

### Implementation Risks

**Risk 1: Incorrect BFS Implementation**
- Likelihood: Low
- Impact: High (wrong results)
- Mitigation: Extensive testing, code review, manual verification
- Contingency: Fix bugs based on test failures

**Risk 2: Power/Ground Filtering Insufficient**
- Likelihood: Medium
- Impact: Medium (performance degradation)
- Mitigation: Comprehensive net name patterns, make configurable
- Contingency: Add more filtering rules based on user feedback

## Open Questions

### Questions for Domain Experts

1. **Multi-Driver Nets:** How should fanin traversal handle nets with multiple drivers (tri-state)? Return all drivers or implement priority logic?
   - **Decision needed by:** Before implementation start
   - **Fallback:** Return all drivers, document behavior

2. **Power/Ground Filtering:** What net naming conventions should be recognized as power/ground?
   - **Decision needed by:** Before implementation start
   - **Fallback:** Common patterns (VDD, VSS, GND, VPWR, VGND, etc.)

3. **Clock Nets:** Should clock nets be filtered like power/ground to avoid expanding clock tree?
   - **Decision needed by:** Before implementation start
   - **Fallback:** No filtering initially, add in P1 if requested

### Technical Questions

1. **Pin-Net Association:** Does `Pin` entity have direct reference to `Net`, or must we query via graph?
   - **Resolution:** Review domain model, may need design aggregate query method

2. **Graph Construction Timing:** When is NetworkX graph populated? At design load or lazily?
   - **Resolution:** Coordinate with E01-F03 implementation

3. **Hop Count Limits:** Should there be a hard maximum hop limit for safety?
   - **Resolution:** Decide in T05 (N-Hop Configuration)

## Implementation Sequence

### Phase 1: Domain Protocol (2 hours)
1. Define `GraphTraverser` protocol in `src/ink/domain/services/graph_traverser.py`
2. Add type hints, docstrings
3. Review with domain model consistency

### Phase 2: Infrastructure Skeleton (1 hour)
1. Create `NetworkXGraphTraverser` class in `src/ink/infrastructure/graph/networkx_graph_traverser.py`
2. Implement constructor, basic structure
3. Add validation for graph parameter

### Phase 3: BFS Implementation (3 hours)
1. Implement `get_fanout()` with BFS algorithm
2. Implement `get_fanin()` with BFS algorithm
3. Add helper methods `_bfs_fanout()`, `_bfs_fanin()`

### Phase 4: Edge Case Handling (1 hour)
1. Add power/ground net filtering
2. Handle unconnected pins, None checks
3. Add cycle detection for loops

### Phase 5: Testing (3 hours)
1. Write unit tests for basic traversal
2. Write unit tests for edge cases
3. Write integration tests with synthetic graphs
4. Add performance benchmarks

### Phase 6: Optimization (1 hour if needed)
1. Profile performance
2. Optimize hot paths if targets not met
3. Add caching if beneficial

**Total Estimate:** 8 hours (with buffer for debugging)

## Success Metrics

### Functional Metrics
- All unit tests pass (target: 15+ tests, 90%+ coverage)
- All integration tests pass (target: 5+ scenarios)
- Correctly handles all documented edge cases

### Performance Metrics
- 1-hop traversal: <100ms on 100K cell design
- 5-hop traversal: <500ms on 100K cell design
- Memory usage: <100MB for deep traversals

### Quality Metrics
- mypy type checking passes with no errors
- All docstrings complete with examples
- Code review approved by team

## Notes and Assumptions

### Assumptions
1. NetworkX graph is pre-built and available from E01-F03
2. `Cell`, `Pin`, `Net` entities are stable in domain model
3. Graph schema follows documented structure (cells as nodes, connectivity as edges)
4. Power/ground nets can be identified by name patterns

### Out of Scope
- Advanced optimization (rustworkx migration) - defer to future
- Semantic boundary detection - handled by P1 features
- Path highlighting - handled by P2 features
- Parallel traversal - not needed for MVP

### Documentation Requirements
- Docstrings for all public methods (with examples)
- Algorithm pseudocode in implementation comments
- Integration guide for application layer consumers
- Performance benchmarking results

### Coordination Needed
- Sync with E01-F03 on graph schema
- Sync with domain model team on entity relationships
- Sync with E03-F01-T02 on integration points
