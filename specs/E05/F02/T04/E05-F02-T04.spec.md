---
id: E05-F02-T04
title: Incremental Search Optimization
type: Task
priority: P0 (MVP)
status: Draft
parent: E05-F02
created: 2025-12-26
estimated_hours: 4
actual_hours:
effort: Small
tags:
  - application
  - performance
  - ux
clickup_task_id: ''
---

# Spec: E05-F02-T04 - Incremental Search Optimization

## 1. Overview

### 1.1 Problem Statement
Real-time search as users type requires special optimization to maintain responsiveness. Each keystroke triggers a new search query, potentially causing 50+ searches in rapid succession. Debouncing, caching, and progressive refinement ensure smooth UX with sub-100ms perceived latency.

### 1.2 Goals
- Debounce search queries to reduce redundant searches
- Cache recent search results for instant retrieval
- Implement progressive prefix refinement for typed sequences
- Maintain < 100ms perceived response time
- Minimize CPU usage during rapid typing

---

## 2. Technical Requirements

### 2.1 Incremental Search Handler

**Location**: `/home/joohan/dev/project-ink/ink/src/ink/application/services/incremental_search.py`

```python
from typing import List, Optional, Callable
from dataclasses import dataclass
import time
from functools import lru_cache
from ink.application.services.search_service import SearchService, SearchFilters, SearchResult

@dataclass
class SearchCache:
    """Cache entry for search results"""
    query: str
    filters: SearchFilters
    results: List[SearchResult]
    timestamp: float

class IncrementalSearchHandler:
    """
    Optimized handler for real-time incremental search.

    Features:
        - Query debouncing to reduce redundant searches
        - Result caching for instant retrieval
        - Progressive prefix refinement
        - Minimum character threshold
    """

    def __init__(
        self,
        search_service: SearchService,
        debounce_ms: int = 150,
        cache_size: int = 50,
        min_query_length: int = 2
    ):
        """
        Initialize incremental search handler.

        Args:
            search_service: Core search service
            debounce_ms: Milliseconds to wait before executing search
            cache_size: Maximum number of cached queries
            min_query_length: Minimum characters to trigger search
        """
        self._search_service = search_service
        self._debounce_ms = debounce_ms
        self._min_query_length = min_query_length

        # Cache: query -> SearchCache
        self._cache: dict[str, SearchCache] = {}
        self._cache_size = cache_size

        # Debounce state
        self._last_query: str = ""
        self._last_search_time: float = 0.0
        self._pending_query: Optional[str] = None

    def search(
        self,
        query: str,
        filters: Optional[SearchFilters] = None,
        on_results: Optional[Callable[[List[SearchResult]], None]] = None
    ) -> List[SearchResult]:
        """
        Execute incremental search with optimizations.

        Args:
            query: Current search query (may be partial)
            filters: Search filters
            on_results: Optional callback for async result delivery

        Returns:
            Search results (may be cached or computed)
        """
        if filters is None:
            filters = SearchFilters()

        # Check minimum length
        if len(query) < self._min_query_length:
            return []

        # Check cache first
        cached = self._get_cached(query, filters)
        if cached is not None:
            if on_results:
                on_results(cached)
            return cached

        # Progressive refinement optimization
        # If query is extension of previous query, filter cached results
        if self._is_prefix_extension(query):
            refined = self._refine_from_cache(query, filters)
            if refined is not None:
                self._cache_results(query, filters, refined)
                if on_results:
                    on_results(refined)
                return refined

        # Execute new search
        results = self._search_service.search(query, filters)

        # Cache results
        self._cache_results(query, filters, results)
        self._last_query = query
        self._last_search_time = time.time()

        if on_results:
            on_results(results)

        return results

    def _get_cached(
        self,
        query: str,
        filters: SearchFilters
    ) -> Optional[List[SearchResult]]:
        """Retrieve cached results if available and fresh"""
        cache_key = self._make_cache_key(query, filters)

        if cache_key in self._cache:
            cache_entry = self._cache[cache_key]

            # Cache valid for 60 seconds
            age = time.time() - cache_entry.timestamp
            if age < 60.0:
                return cache_entry.results
            else:
                # Expired, remove from cache
                del self._cache[cache_key]

        return None

    def _cache_results(
        self,
        query: str,
        filters: SearchFilters,
        results: List[SearchResult]
    ) -> None:
        """Cache search results with LRU eviction"""
        cache_key = self._make_cache_key(query, filters)

        # Evict oldest if cache full
        if len(self._cache) >= self._cache_size:
            oldest_key = min(self._cache.keys(), key=lambda k: self._cache[k].timestamp)
            del self._cache[oldest_key]

        self._cache[cache_key] = SearchCache(
            query=query,
            filters=filters,
            results=results,
            timestamp=time.time()
        )

    def _is_prefix_extension(self, query: str) -> bool:
        """Check if query extends previous query by typing"""
        return (
            len(query) > len(self._last_query) and
            query.startswith(self._last_query) and
            len(self._last_query) >= self._min_query_length
        )

    def _refine_from_cache(
        self,
        query: str,
        filters: SearchFilters
    ) -> Optional[List[SearchResult]]:
        """
        Filter previous results for prefix extension.

        If user typed "clk" then "clk_", we can filter previous
        results instead of searching again.
        """
        # Get cached results from previous query
        prev_cache_key = self._make_cache_key(self._last_query, filters)
        if prev_cache_key not in self._cache:
            return None

        prev_results = self._cache[prev_cache_key].results

        # Filter results matching new query
        refined = []
        for result in prev_results:
            # Check if result still matches extended query
            if query.lower() in result.name.lower():
                refined.append(result)
            elif len(refined) >= filters.max_results:
                break

        return refined if refined else None

    def _make_cache_key(self, query: str, filters: SearchFilters) -> str:
        """Generate cache key from query and filters"""
        filter_key = (
            f"{filters.include_cells}:"
            f"{filters.include_nets}:"
            f"{filters.include_ports}:"
            f"{filters.include_pins}:"
            f"{filters.max_results}"
        )
        return f"{query}|{filter_key}"

    def clear_cache(self) -> None:
        """Clear all cached results"""
        self._cache.clear()
        self._last_query = ""

    def get_cache_stats(self) -> dict:
        """Get cache statistics for monitoring"""
        return {
            "cache_size": len(self._cache),
            "max_cache_size": self._cache_size,
            "last_query": self._last_query,
            "queries_cached": len(self._cache)
        }
```

### 2.2 Debouncing Strategy

For UI integration, debouncing is typically handled at the presentation layer using QTimer:

```python
# Example UI integration (not part of this task, but shown for context)
class SearchPanel(QWidget):
    def __init__(self):
        self._debounce_timer = QTimer()
        self._debounce_timer.setSingleShot(True)
        self._debounce_timer.timeout.connect(self._execute_search)

        self._search_input.textChanged.connect(self._on_text_changed)

    def _on_text_changed(self, text: str):
        # Restart debounce timer on each keystroke
        self._debounce_timer.stop()
        self._debounce_timer.start(150)  # 150ms debounce

    def _execute_search(self):
        query = self._search_input.text()
        results = self._incremental_handler.search(query)
        self._display_results(results)
```

### 2.3 Performance Requirements

| Metric | Target | Strategy |
|--------|--------|----------|
| Perceived latency | < 100ms | Debouncing + caching |
| Cache hit rate | > 50% for typical usage | LRU cache with prefix refinement |
| Memory overhead | < 10MB | Limit cache to 50 entries |
| CPU usage during typing | < 10% | Debounce prevents redundant searches |

---

## 3. Testing Requirements

### 3.1 Unit Tests

**Location**: `/home/joohan/dev/project-ink/ink/tests/unit/application/services/test_incremental_search.py`

```python
import pytest
import time
from ink.application.services.incremental_search import IncrementalSearchHandler
from ink.application.services.search_service import SearchService, SearchFilters

@pytest.fixture
def handler(sample_design):
    """Create handler with sample design"""
    search_service = SearchService(sample_design)
    return IncrementalSearchHandler(
        search_service=search_service,
        debounce_ms=150,
        cache_size=50
    )

class TestIncrementalSearchHandler:
    def test_minimum_query_length(self, handler):
        results = handler.search("c")  # Too short
        assert len(results) == 0

        results = handler.search("cl")  # Long enough
        assert len(results) > 0

    def test_cache_hit(self, handler):
        # First search
        results1 = handler.search("clk")

        # Second identical search (should hit cache)
        results2 = handler.search("clk")

        assert results1 == results2
        stats = handler.get_cache_stats()
        assert stats["queries_cached"] > 0

    def test_progressive_refinement(self, handler):
        # Type "cl" then "clk"
        results1 = handler.search("cl")
        results2 = handler.search("clk")  # Should refine from cached "cl"

        # Results2 should be subset of results1 (or equal)
        names1 = {r.name for r in results1}
        names2 = {r.name for r in results2}
        # All clk results should have been in cl results
        assert names2.issubset(names1) or len(names2) == 0

    def test_cache_expiration(self, handler):
        # Mock time to test expiration
        handler.search("clk")

        # Manually expire cache entry
        for cache_entry in handler._cache.values():
            cache_entry.timestamp = time.time() - 65  # 65 seconds ago

        # Should not hit cache
        cached = handler._get_cached("clk", SearchFilters())
        assert cached is None

    def test_cache_size_limit(self, handler):
        # Fill cache beyond limit
        for i in range(60):  # More than cache_size=50
            handler.search(f"q{i:02d}")

        stats = handler.get_cache_stats()
        assert stats["cache_size"] <= handler._cache_size

    def test_cache_clear(self, handler):
        handler.search("clk")
        assert len(handler._cache) > 0

        handler.clear_cache()
        assert len(handler._cache) == 0

    def test_different_filters_separate_cache(self, handler):
        filters1 = SearchFilters(include_cells=True, include_nets=False)
        filters2 = SearchFilters(include_cells=False, include_nets=True)

        results1 = handler.search("clk", filters1)
        results2 = handler.search("clk", filters2)

        # Should have different results
        assert results1 != results2

        # Should have separate cache entries
        assert len(handler._cache) == 2

    def test_callback_invocation(self, handler):
        callback_results = []

        def on_results(results):
            callback_results.append(results)

        handler.search("clk", on_results=on_results)

        assert len(callback_results) == 1
        assert len(callback_results[0]) > 0
```

### 3.2 Performance Tests

```python
class TestIncrementalSearchPerformance:
    def test_search_latency(self, handler, benchmark):
        """Verify search completes in < 100ms"""
        def search():
            return handler.search("clk")

        result = benchmark(search)
        assert benchmark.stats.median < 0.1  # 100ms

    def test_cache_hit_latency(self, handler, benchmark):
        """Verify cache hit is nearly instant"""
        # Warm up cache
        handler.search("clk")

        def cached_search():
            return handler.search("clk")

        result = benchmark(cached_search)
        assert benchmark.stats.median < 0.001  # 1ms

    def test_rapid_typing_simulation(self, handler):
        """Simulate user typing 'clk_buf_0' rapidly"""
        queries = ["cl", "clk", "clk_", "clk_b", "clk_bu", "clk_buf", "clk_buf_", "clk_buf_0"]

        start = time.time()
        for query in queries:
            handler.search(query)
        elapsed = time.time() - start

        # Should complete all searches quickly
        assert elapsed < 0.5  # 500ms for 8 searches
```

---

## 4. Dependencies

- **Upstream**:
  - E05-F02-T03 (SearchService)
- **Downstream**:
  - E05-F01 (Search Panel UI uses IncrementalSearchHandler)

---

## 5. Acceptance Criteria

- [ ] `IncrementalSearchHandler` wraps `SearchService`
- [ ] Minimum query length (2 chars) enforced
- [ ] Search results cached with query + filters as key
- [ ] Cache entries expire after 60 seconds
- [ ] Cache size limited to 50 entries with LRU eviction
- [ ] Progressive refinement filters cached results for prefix extensions
- [ ] `clear_cache()` method implemented
- [ ] `get_cache_stats()` returns cache metrics
- [ ] Cached searches return in < 1ms
- [ ] New searches return in < 100ms
- [ ] Rapid typing (8 queries) completes in < 500ms
- [ ] All unit tests passing with > 85% coverage

---

## 6. Implementation Notes

### 6.1 Design Decisions
- Debouncing handled in UI layer (QTimer) for better separation
- Cache uses simple dict (not LRU dict) for MVP simplicity
- Progressive refinement only for simple prefix extensions

### 6.2 Future Enhancements (Post-MVP)
- Background search with result streaming
- Intelligent prefetch based on common query patterns
- Persistent cache across sessions
- Query suggestion/autocomplete based on history

---

## Revision History
| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-12-26 | 0.1 | Claude | Initial task creation from E05-F02 split |
