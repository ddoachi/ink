# E05-F02-T01: Trie Index Implementation - Pre-Implementation Documentation

## Document Metadata
- **Task**: E05-F02-T01 - Trie Index Implementation
- **Status**: Pre-Implementation Planning
- **Created**: 2025-12-26
- **Last Updated**: 2025-12-26
- **Author**: Claude Sonnet 4.5

---

## 1. Overview

### 1.1 Task Summary

Implement a generic Trie (prefix tree) data structure that provides O(m) prefix search performance for the search engine. This is a foundational infrastructure component that enables sub-50ms autocomplete and incremental search across 100K+ design objects (cells, nets, ports, pins).

### 1.2 Problem Context

Traditional search approaches using linear scans or simple hash maps fail to provide the real-time prefix matching required for autocomplete. A trie optimizes for prefix queries by sharing common prefixes in a tree structure, enabling fast lookups regardless of dataset size.

**Why Trie vs Alternatives**:
- **Hash Map**: O(1) exact match but no prefix support
- **Sorted List + Binary Search**: O(log n + k) but slower for large datasets
- **Full-Text Index (Whoosh/Elasticsearch)**: Overkill for simple prefix matching, external dependency
- **Trie**: O(m) where m = query length, perfect for autocomplete

### 1.3 Success Criteria

- Prefix search returns all matches in < 50ms for 100K entries
- Memory usage < 30MB for 100K words
- Generic implementation supports any value type
- Thread-safe for concurrent reads (important for UI responsiveness)

---

## 2. Technical Approach

### 2.1 Core Data Structure Design

**Trie Node Structure**:
```python
class TrieNode(Generic[T]):
    children: Dict[str, TrieNode[T]]  # Character → child node
    is_end_of_word: bool               # Marks valid word boundary
    value: Optional[T]                 # Associated data at word end
```

**Why This Design**:
1. **Dictionary for children**: Fast O(1) character lookup, handles arbitrary character sets
2. **Generic type T**: Allows storing Cell, Net, Port objects directly
3. **Separate value storage**: Only leaf nodes store values, saves memory
4. **is_end_of_word flag**: Distinguishes between "car" and "card" when both exist

### 2.2 Key Operations

#### Insert Operation
```
Time Complexity: O(m) where m = word length
Space: O(m) worst case (new branch), amortized O(1) (shared prefix)

Algorithm:
1. Start at root
2. For each character in word:
   - Create child node if doesn't exist
   - Move to child node
3. Mark final node as word end
4. Store associated value
```

#### Prefix Search Operation
```
Time Complexity: O(m + n) where m = prefix length, n = result count
Space: O(n) for result collection

Algorithm:
1. Navigate to prefix node (O(m))
2. DFS traversal from prefix node (O(n))
3. Collect all words until max_results reached
4. Return sorted results
```

**Why DFS vs BFS**:
- DFS uses less memory (stack vs queue)
- Natural alphabetical ordering with sorted children iteration
- Early termination easier (stop when result limit reached)

### 2.3 Case-Insensitive Variant

**Strategy**: Normalize to lowercase on insertion and search

**Tradeoff Analysis**:
- **Pro**: Simple implementation, no memory overhead
- **Con**: Loses original case (acceptable for search matching)
- **Alternative**: Store both original and normalized (doubles memory)

**Decision**: Use normalization for MVP, original case preserved in value object

### 2.4 Memory Optimization Techniques

**Problem**: 100K words × avg 15 chars × 8 bytes/char = 12MB just for strings
- Add node objects, dictionaries → easily 100MB+

**Optimizations**:
1. **String Interning**: Python's `sys.intern()` for common substrings (cell types, pin names)
2. **Character Codes**: Use single-char keys instead of strings in children dict
3. **Node Pooling**: Pre-allocate node objects to reduce allocator overhead (if profiling shows benefit)
4. **Lazy Children Dict**: Only create children dict when needed (saves empty dicts)

**Expected Savings**: 30-50% memory reduction with interning alone

---

## 3. Implementation Strategy

### 3.1 Development Phases

#### Phase 1: Core Trie (2 hours)
**Deliverables**:
- `TrieNode` class with generic type
- `Trie` class with `insert()` and `search_exact()`
- Basic unit tests

**Success Check**:
- Insert 1000 words, verify exact match works
- Memory profiling shows reasonable overhead

#### Phase 2: Prefix Search (2 hours)
**Deliverables**:
- `search_prefix()` with DFS collection
- `max_results` limit enforcement
- Sorted result ordering

**Success Check**:
- Prefix "test" returns all "test*" words
- Results limited correctly
- Alphabetical ordering verified

#### Phase 3: Case-Insensitive & Magic Methods (1 hour)
**Deliverables**:
- `CaseInsensitiveTrie` subclass
- `__len__()`, `__contains__()` implementations
- Edge case handling (empty strings, unicode)

**Success Check**:
- Case-insensitive matching works
- `len(trie)` and `"word" in trie` work correctly

#### Phase 4: Performance Testing (1 hour)
**Deliverables**:
- Benchmark with 100K entries
- Memory profiling
- Performance optimization if needed

**Success Check**:
- Prefix search < 50ms
- Memory < 30MB

### 3.2 File Organization

```
src/ink/infrastructure/search/
├── __init__.py
└── trie_index.py          # TrieNode, Trie, CaseInsensitiveTrie

tests/unit/infrastructure/search/
├── __init__.py
└── test_trie_index.py     # Comprehensive unit tests
```

---

## 4. Design Decisions

### 4.1 Generic Type vs Concrete Cell/Net Types

**Decision**: Use generic `Trie[T]` with TypeVar

**Alternatives**:
1. **Separate TrieCell, TrieNet classes**: Too much duplication
2. **Store IDs only**: Requires secondary lookup, slower
3. **Any type**: No type safety

**Rationale**: Generics provide type safety and reusability. SearchService can create `Trie[Cell]`, `Trie[Net]` with full IDE support.

### 4.2 Result Ordering Strategy

**Decision**: Alphabetical sorting with `sorted(children.items())`

**Alternatives**:
1. **Insertion order**: Unpredictable for users
2. **Frequency-based**: Requires usage tracking (post-MVP)
3. **Relevance scoring**: Handled by SearchService layer

**Rationale**: Alphabetical is deterministic and expected by users. Future: delegate sorting to SearchService for relevance ranking.

### 4.3 Max Results Enforcement

**Decision**: Early termination during DFS traversal

**Why**:
- Avoids collecting 10K results just to truncate to 100
- Significant performance win for large result sets
- Minimal code complexity

**Implementation**:
```python
if len(results) >= max_results:
    return  # Stop DFS early
```

### 4.4 Thread Safety Approach

**Decision**: Read-only after construction (insert during indexing phase only)

**Why**:
- Simplifies design (no locking needed)
- UI searches only read from trie
- Re-index on design reload (rare operation)

**Post-MVP**: If dynamic updates needed, use read-write lock or immutable trie with copy-on-write

---

## 5. Testing Strategy

### 5.1 Unit Test Coverage

**Core Functionality** (must have):
- Insert single word and verify
- Insert multiple words with shared prefixes
- Exact match returns correct value
- Exact match returns None for non-existent word
- Prefix search finds all matches
- Empty prefix returns all words (up to limit)
- Max results limit enforced correctly

**Edge Cases** (must have):
- Empty string handling
- Single character queries
- Unicode characters (测试, Müller)
- Special characters in strings
- Very long strings (1000+ chars)
- Duplicate insertions (overwrite behavior)

**Case Sensitivity** (must have):
- Case-sensitive trie distinguishes "Hello" vs "hello"
- Case-insensitive trie matches "HELLO", "hello", "HeLLo"

**Magic Methods** (should have):
- `len(trie)` tracks unique word count
- `"word" in trie` checks existence
- Overwriting word doesn't increase size

### 5.2 Performance Tests

**Benchmark Scenarios**:
1. Insert 100K unique words (measure time + memory)
2. Prefix search with 1-char prefix (worst case - many matches)
3. Prefix search with 10-char prefix (best case - few matches)
4. Exact match in 100K word dataset

**Acceptance Criteria**:
- Insert: < 1ms per word average
- Prefix search (100 results): < 50ms
- Exact match: < 1ms
- Memory: < 30MB for 100K words

**Profiling Tools**:
- `pytest-benchmark` for timing
- `memory_profiler` for heap analysis
- `tracemalloc` for allocation tracking

### 5.3 Test Data Generation

```python
def generate_test_words(count: int, prefix: str = "cell_") -> list[str]:
    """Generate realistic cell names for testing"""
    return [f"{prefix}{i:06d}" for i in range(count)]

def generate_realistic_netlist_names() -> dict[str, list[str]]:
    """Cell types, net names, pin names from real designs"""
    return {
        'cells': ['INV_X1', 'NAND2_X1', 'NOR2_X1', ...],
        'nets': ['clk', 'data_bus_0', 'addr_reg_out', ...],
        'pins': ['A', 'B', 'Y', 'Q', 'D', ...]
    }
```

---

## 6. Integration Points

### 6.1 Downstream Consumers

**SearchService (E05-F02-T03)**:
```python
class SearchService:
    def __init__(self, design: Design):
        self._cell_trie = Trie[Cell]()
        self._net_trie = Trie[Net]()

        for cell in design.cells:
            self._cell_trie.insert(cell.name, cell)
```

**Expected Usage Pattern**:
1. Create trie instances in SearchService `__init__`
2. Populate during design load (one-time indexing)
3. Query from UI thread during search
4. Re-create trie on design reload

### 6.2 Dependencies

**Upstream**: None (pure Python, standard library only)

**Concurrent Usage**:
- Multiple threads may call `search_prefix()` simultaneously
- No writes after initial indexing
- No locking needed (Python GIL + read-only guarantee)

---

## 7. Risk Analysis

### 7.1 Performance Risks

#### Risk 1: Memory Overhead Exceeds Target
**Impact**: High (OOM crashes, unusable for large designs)
**Probability**: Medium (depends on actual netlist name patterns)

**Mitigation**:
- Profile early with 100K synthetic data
- Implement string interning from day 1
- Monitor memory in CI benchmarks

**Contingency**:
- Switch to compressed trie (PATRICIA tree)
- Store only prefixes, not full words
- External storage (SQLite full-text search)

#### Risk 2: Search Latency > 50ms
**Impact**: Medium (poor autocomplete UX, but functional)
**Probability**: Low (Trie is fast, but depends on result count)

**Mitigation**:
- Aggressive `max_results` limiting (default 100)
- Early termination in DFS
- Benchmark with worst-case prefix ("a" matches everything)

**Contingency**:
- Reduce max_results to 50
- Add debouncing in UI (150ms delay before search)
- Pre-compute popular prefixes

### 7.2 Implementation Risks

#### Risk 3: Generic Type Complexity
**Impact**: Low (development slowdown, type errors)
**Probability**: Low (Python generics are well-supported in 3.10+)

**Mitigation**:
- Use simple TypeVar, avoid complex bounds
- Extensive type hint testing with mypy
- Examples in docstrings

**Contingency**:
- Fall back to `Trie[Any]` if type issues arise
- Document expected types in comments

---

## 8. Future Enhancements (Post-MVP)

### 8.1 Advanced Features

**Fuzzy Matching**:
- Levenshtein distance for typo tolerance
- "clk_buf" matches "clk_buf_0" even with extra chars
- Implementation: Modified DFS with edit distance tracking

**Deletion Support**:
- Remove words from trie (for dynamic design editing)
- Challenges: Node cleanup to avoid memory leaks
- Solution: Reference counting or lazy deletion with periodic compaction

**Serialization**:
- Save/load trie to disk for persistent caching
- Formats: Pickle (simple), JSON (portable), Protocol Buffers (compact)
- Benefit: Instant load for large designs (skip indexing phase)

### 8.2 Optimization Opportunities

**Compressed Trie (PATRICIA)**:
- Store edge labels as strings instead of single chars
- Reduces node count by 50-80%
- More complex implementation

**Array-Based Storage**:
- Replace dict with fixed-size array for ASCII
- `children: list[TrieNode]` with 256 slots
- Faster lookup but wastes memory for sparse children

**Concurrent Trie**:
- Lock-free trie for multi-threaded writes
- Use atomic compare-and-swap for node updates
- Only needed if dynamic design editing is added

---

## 9. Acceptance Checklist

### 9.1 Code Completeness

- [ ] `TrieNode[T]` class implemented with generic type
- [ ] `Trie[T]` class with insert, search_exact, search_prefix
- [ ] `CaseInsensitiveTrie[T]` subclass implemented
- [ ] `__len__()`, `__contains__()` magic methods
- [ ] Type hints on all public methods
- [ ] Docstrings with examples

### 9.2 Testing

- [ ] Unit tests cover all public methods
- [ ] Edge cases tested (empty, unicode, special chars)
- [ ] Case-sensitive vs case-insensitive behavior verified
- [ ] Performance benchmark with 100K entries
- [ ] Memory profiling shows < 30MB
- [ ] Test coverage > 90%

### 9.3 Performance

- [ ] Prefix search < 50ms for 100K entries
- [ ] Memory usage < 30MB for 100K words
- [ ] Insert operation < 1ms average
- [ ] Exact match < 1ms

### 9.4 Documentation

- [ ] Docstrings explain time complexity
- [ ] Usage examples in module docstring
- [ ] Type hints enable IDE autocomplete
- [ ] README section on trie performance characteristics

---

## 10. Open Questions

### 10.1 Design Questions

**Q1**: Should we support wildcard patterns in the trie itself?
- **Context**: Currently trie only does prefix matching
- **Options**:
  - A) Keep trie simple, wildcards in PatternMatcher layer
  - B) Add wildcard support to trie (complex)
- **Recommendation**: Option A (separation of concerns)

**Q2**: How to handle very long names (> 1000 chars)?
- **Context**: Some auto-generated nets may have long names
- **Options**:
  - A) No limit, trust data
  - B) Truncate to 1000 chars with warning
  - C) Store hash instead of full string
- **Recommendation**: Option A for MVP, monitor in practice

**Q3**: Should empty prefix ("") return all words?
- **Context**: Useful for "show all" but expensive
- **Options**:
  - A) Return all (up to max_results)
  - B) Return empty list
  - C) Raise ValueError
- **Recommendation**: Option A (consistent with prefix semantics)

### 10.2 Integration Questions

**Q4**: Who owns trie lifecycle - SearchService or separate IndexManager?
- **Recommendation**: SearchService for MVP, refactor to IndexManager if complexity grows

**Q5**: Should we expose raw trie to UI layer or only through SearchService?
- **Recommendation**: Hide behind SearchService (encapsulation)

---

## Appendix A: Algorithm Walkthrough

### Example: Insert "cat", "car", "card", "dog"

**Step 1: Insert "cat"**
```
root
  └─ c
      └─ a
          └─ t* (value: <cat_object>)
```

**Step 2: Insert "car"**
```
root
  └─ c
      └─ a
          ├─ t* (value: <cat_object>)
          └─ r* (value: <car_object>)
```

**Step 3: Insert "card"**
```
root
  └─ c
      └─ a
          ├─ t* (value: <cat_object>)
          └─ r* (value: <car_object>)
              └─ d* (value: <card_object>)
```

**Step 4: Insert "dog"**
```
root
  ├─ c
  │   └─ a
  │       ├─ t* (value: <cat_object>)
  │       └─ r* (value: <car_object>)
  │           └─ d* (value: <card_object>)
  └─ d
      └─ o
          └─ g* (value: <dog_object>)
```

### Example: Search Prefix "ca"

**Navigation Phase** (O(m) where m=2):
```
root → c → a  (found prefix node)
```

**Collection Phase** (DFS from 'a' node):
```
Visit a→t*: collect "cat"
Visit a→r*: collect "car"
Visit a→r→d*: collect "card"
Return: [("cat", <cat_object>), ("car", <car_object>), ("card", <card_object>)]
```

---

## Appendix B: Performance Analysis

### Memory Calculation

**Per-Word Memory**:
```
TrieNode object: ~56 bytes (Python object overhead)
children dict: ~232 bytes (empty dict)
value slot: ~8 bytes
is_end_of_word: ~1 byte
Total per node: ~300 bytes
```

**For "hello" (5 chars, 5 nodes)**:
```
5 nodes × 300 bytes = 1,500 bytes per word (worst case, no sharing)
```

**With Prefix Sharing** (e.g., "hello" + "help"):
```
Shared nodes: h-e-l (3 nodes)
Unique nodes: l-o (2) + p (1) = 3 nodes
Total: 6 nodes for 2 words = 900 bytes per word
```

**100K Words Estimate**:
```
Average word length: 15 chars
Average sharing: 30% (conservative)
Unique nodes: 100K × 15 × 0.7 = 1,050K nodes
Memory: 1,050K × 300 bytes = 315 MB

With optimizations (interning, slots): ~100-150 MB
```

**Conclusion**: Need optimizations to hit 30MB target or relax to 100MB

### Time Complexity Analysis

**Insert**:
```
Best case: O(1) - single char word
Worst case: O(m) - m-char word, all new nodes
Average: O(m) where m ≈ 15 for cell names
```

**Search Prefix**:
```
Navigation: O(m) where m = prefix length
Collection: O(n) where n = result count
Total: O(m + n)

Example: prefix "clk" with 100 results
3 + 100 = 103 operations ≈ < 1ms
```

**Exact Match**:
```
Navigate to word: O(m)
Check is_end_of_word: O(1)
Total: O(m)

Example: "clk_buf_main" = 12 chars ≈ < 0.1ms
```

---

## Document Revision History

| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-12-26 | 1.0 | Claude Sonnet 4.5 | Initial pre-implementation documentation |

---

**End of Pre-Implementation Documentation**
