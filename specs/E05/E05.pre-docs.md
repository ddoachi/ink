# E05 - Search & Navigation: Pre-Implementation Planning

## Document Metadata
- **Epic ID**: E05
- **Epic Name**: Search & Navigation
- **Document Type**: Pre-Implementation Planning
- **Status**: Draft
- **Created**: 2025-12-26
- **Last Updated**: 2025-12-26

---

## 1. Overview

### 1.1 Epic Summary

The Search & Navigation epic implements a critical capability for Ink: finding and navigating to objects (cells, pins, nets, ports) in large gate-level netlists. Engineers working with netlists containing hundreds of thousands of cells need efficient search with real-time filtering, wildcard pattern matching, and automatic navigation to results.

### 1.2 Strategic Importance

This is a **P0 MVP feature** that directly addresses a fundamental usability requirement. Without effective search:
- Users cannot efficiently locate specific objects in large designs
- Manual navigation becomes impractical beyond small netlists
- The incremental exploration model loses value without jump points
- Overall tool productivity suffers significantly

### 1.3 Success Criteria

**Primary Metrics:**
- Search response time: <100ms for result display
- Navigation completion: <200ms to pan/zoom to target
- Search capacity: Handle 10K+ objects in <200ms
- History persistence: Survives application restarts

**User Experience Goals:**
- Keyboard-first workflow (Ctrl+F to open, Enter to navigate, Esc to close)
- Incremental feedback (results update as user types)
- Intelligent result limiting (prevent UI overwhelm)
- Context preservation (selected object remains visible)

---

## 2. Architecture Decisions

### 2.1 Core Design Choices

#### Decision 1: Search Panel Location - Dockable Widget vs Modal Dialog

**Options Considered:**
1. **Modal Dialog** - Traditional search dialog that blocks main window
2. **Dockable Panel** - Non-modal panel that can be docked or floated
3. **Inline Search Bar** - Embedded in toolbar or canvas

**Selected: Dockable Panel**

**Rationale:**
- Non-blocking: Users can view results while keeping canvas visible
- Flexible positioning: Can dock to side or float as needed
- Persistent state: Panel can remain open across multiple searches
- Better for iterative exploration: Search → Navigate → Refine → Repeat
- Aligns with modern IDE patterns (VS Code, Eclipse)

**Trade-offs:**
- Slightly more complex UI setup than modal dialog
- Requires more screen real estate
- Need to manage panel state (open/closed, docked/floating)

**Implementation Note:**
Use `QDockWidget` with default right-side docking. Store dock state in settings for persistence.

---

#### Decision 2: Indexing Strategy - Lazy vs Pre-built

**Options Considered:**
1. **No Index** - Linear search through all objects on every query
2. **Lazy Index** - Build index on first search, cache for subsequent searches
3. **Pre-built Index** - Build index during netlist load
4. **Incremental Index** - Update index as graph changes (expansion/collapse)

**Selected: Pre-built Index with Incremental Updates**

**Rationale:**
- **Pre-built benefits:**
  - Predictable first-search performance
  - Netlist load is already a heavy operation (user expects delay)
  - Amortizes indexing cost across all searches

- **Incremental updates:**
  - Expansion/collapse operations modify visible objects
  - Re-indexing only new objects keeps index accurate
  - Minimal overhead per expansion (typically <100 new objects)

**Trade-offs:**
- Increases netlist load time (acceptable for P0)
- Memory overhead for index structures (minimal vs total netlist size)
- Complexity in managing index consistency

**Implementation Note:**
Build index in `SearchIndex` class during graph construction. Expose `add_objects()` and `remove_objects()` methods called by expansion service.

---

#### Decision 3: Pattern Matching - Regex vs Custom Wildcard

**Options Considered:**
1. **Python `fnmatch`** - Standard library wildcard matching
2. **Full Regex** - Allow users to write regex patterns directly
3. **Wildcard-to-Regex** - Convert simple wildcards (`*`, `?`) to regex internally
4. **Custom Trie-based** - Build pattern matching into trie structure

**Selected: Wildcard-to-Regex (Option 3)**

**Rationale:**
- User-friendly: Engineers familiar with `*clk*` patterns from EDA tools
- Flexible backend: Regex provides performance and feature extensibility
- Error handling: Can validate patterns and provide helpful error messages
- Future-proof: Can add regex mode later without breaking existing queries

**Trade-offs:**
- Slightly more complex than `fnmatch` (negligible)
- Regex compilation overhead (mitigated by caching)

**Implementation Note:**
```python
def pattern_to_regex(query: str) -> re.Pattern:
    # Escape special regex chars except * and ?
    escaped = re.escape(query)
    # Convert wildcards: * -> .*, ? -> .
    pattern = escaped.replace(r'\*', '.*').replace(r'\?', '.')
    return re.compile(f'^{pattern}$', re.IGNORECASE)
```

---

#### Decision 4: Search Scope - Full Netlist vs Visible Objects Only

**Options Considered:**
1. **Visible Only** - Search only expanded/visible objects
2. **Full Netlist** - Search all objects regardless of visibility
3. **User Configurable** - Toggle between both modes

**Selected: Full Netlist (Option 2)**

**Rationale:**
- Primary use case: Finding objects user doesn't know location of
- Visible-only defeats purpose of search as discovery tool
- Auto-expansion on navigation handles bringing hidden objects into view
- Simpler mental model: "Search finds everything"

**Trade-offs:**
- Requires auto-expansion logic on navigation (already needed)
- Potentially more results (handled by result limiting)

**Future Enhancement:**
Add "Search Visible Only" checkbox for advanced users who want to filter already-expanded regions.

---

#### Decision 5: Data Structure - Trie vs Hash Map

**Options Considered:**
1. **Hash Map Only** - `Dict[str, Object]` for exact name lookup
2. **Trie + Hash Map** - Trie for prefix matching, hash for exact lookup
3. **Suffix Tree** - Advanced structure for arbitrary substring search

**Selected: Hash Map Only (MVP), Trie in P1**

**Rationale:**
- MVP wildcard patterns handle most use cases (`*clk*`, `U_ALU_*`)
- Hash map + regex matching sufficient for 10K objects in <100ms
- Trie adds complexity without proportional P0 value
- Can optimize later with trie if profiling shows need

**Trade-offs:**
- Slightly slower prefix search (acceptable for MVP scale)
- Trie would enable real-time autocomplete (defer to P1)

**Performance Analysis:**
```
100K objects × regex match @ 1μs = 100ms (within budget)
1M objects would require trie optimization
```

---

### 2.2 Component Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                        Main Window                          │
│  ┌───────────────────────────┬──────────────────────────┐   │
│  │                           │   Search Panel (Dock)    │   │
│  │                           │  ┌────────────────────┐  │   │
│  │                           │  │ Search Input       │  │   │
│  │    Schematic Canvas       │  │ [*clk*]     [x]    │  │   │
│  │                           │  ├────────────────────┤  │   │
│  │                           │  │ Filters:           │  │   │
│  │                           │  │ ☑ Cells  ☑ Pins    │  │   │
│  │                           │  │ ☑ Nets   ☑ Ports   │  │   │
│  │                           │  ├────────────────────┤  │   │
│  │                           │  │ Results (247)      │  │   │
│  │                           │  │ • clk_gate_0       │  │   │
│  │                           │  │ • clk_gate_1       │  │   │
│  │                           │  │ • sys_clk (net)    │  │   │
│  │                           │  │ ...                │  │   │
│  │                           │  └────────────────────┘  │   │
│  └───────────────────────────┴──────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘

Service Layer:
┌──────────────┐    ┌───────────────┐    ┌──────────────┐
│SearchService │───>│ SearchIndex   │    │  Navigator   │
│              │    │  - cell_map   │    │              │
│ - search()   │    │  - pin_map    │<───│- navigate_to │
│ - navigate() │    │  - net_map    │    │- center_on   │
└──────────────┘    └───────────────┘    └──────────────┘
       │                                         │
       └─────────────────┬───────────────────────┘
                         ▼
                  ┌─────────────┐
                  │ Graph Model │
                  └─────────────┘
```

**Key Components:**

1. **SearchPanel (UI)**: PySide6 dockable widget
   - Input field with debouncing
   - Filter checkboxes
   - Results list with item selection
   - History dropdown

2. **SearchService (Business Logic)**:
   - Orchestrates search operations
   - Applies filters
   - Manages history
   - Coordinates with Navigator

3. **SearchIndex (Data)**:
   - Pre-built maps for O(1) lookup
   - Pattern matching logic
   - Result ranking/sorting

4. **Navigator (Integration)**:
   - Handles expansion of hidden objects
   - Pans/zooms canvas to target
   - Updates selection state

---

## 3. Implementation Strategy

### 3.1 Phased Development Approach

#### Phase 1: Foundation (Week 1)
**Goal**: Basic search infrastructure without UI

**Deliverables:**
- `SearchIndex` class with hash map storage
- Pattern-to-regex conversion function
- Unit tests for pattern matching
- Index building during graph construction

**Acceptance:**
- Index builds for 10K+ object test netlist
- Pattern matching passes test suite (exact, prefix, suffix, substring)
- Memory profiling shows acceptable overhead (<10% of graph size)

**Files Created:**
- `src/ink/services/search/__init__.py`
- `src/ink/services/search/index.py`
- `src/ink/services/search/patterns.py`
- `tests/services/search/test_index.py`
- `tests/services/search/test_patterns.py`

---

#### Phase 2: Search Service (Week 1-2)
**Goal**: Search logic with filtering and result management

**Deliverables:**
- `SearchService` class
- Filter implementation (by object type)
- Result limiting and sorting
- Search history management
- Integration tests with mock graph

**Acceptance:**
- Search returns results in <100ms for 10K objects
- Filters correctly exclude object types
- History stores last 10 unique queries
- Results sorted by relevance (exact match first, then alphabetical)

**Files Created:**
- `src/ink/services/search/service.py`
- `src/ink/services/search/models.py` (SearchFilters, SearchResult)
- `src/ink/services/search/history.py`
- `tests/services/search/test_service.py`

---

#### Phase 3: Search Panel UI (Week 2)
**Goal**: User interface for search

**Deliverables:**
- `SearchPanel` dockable widget
- Search input with debouncing (250ms)
- Filter checkboxes
- Results list widget
- History dropdown
- Keyboard shortcuts (Ctrl+F, Esc, Enter)

**Acceptance:**
- Panel docks to right side by default
- Input debouncing prevents search spam
- Results list displays with type icons
- Keyboard navigation works (arrow keys, Enter)
- Panel state persists across sessions

**Files Created:**
- `src/ink/ui/panels/search_panel.py`
- `src/ink/ui/widgets/search_input.py` (debounced input)
- `tests/ui/panels/test_search_panel.py`

---

#### Phase 4: Navigation Integration (Week 2-3)
**Goal**: Navigate to search results

**Deliverables:**
- `Navigator` class (or extend existing navigation service)
- Auto-expansion for hidden objects
- Pan/zoom to center on target
- Selection state update
- Visual feedback (highlight, flash)

**Acceptance:**
- Clicking result selects object in canvas
- Hidden objects auto-expand before navigation
- View centers on object with appropriate zoom
- Navigation completes in <200ms
- Undo/redo includes navigation operations

**Files Created:**
- `src/ink/services/navigation/__init__.py`
- `src/ink/services/navigation/navigator.py`
- `tests/services/navigation/test_navigator.py`

**Integration Points:**
- Calls `ExpansionService` for auto-expand
- Calls `CanvasView.centerOn()` for panning
- Updates `SelectionModel` for highlighting

---

#### Phase 5: Polish & Optimization (Week 3)
**Goal**: Performance tuning and UX refinements

**Deliverables:**
- Incremental index updates on expansion
- Result caching for repeated queries
- Error handling and user feedback
- Loading indicators for slow operations
- Accessibility improvements (ARIA labels, focus management)

**Acceptance:**
- Index update after expansion <10ms
- Repeated queries return instantly (cached)
- Error messages shown for invalid patterns
- Loading spinner for >200ms operations
- Screen reader announces result counts

**Files Modified:**
- All Phase 1-4 files
- `src/ink/core/graph/graph.py` (index update hooks)

---

### 3.2 Integration Points

#### With E03 (Expansion Service)
```python
# navigator.py
async def navigate_to(self, object_id: str):
    obj = self.graph.get_object(object_id)

    # If object not visible, expand to show it
    if not obj.is_visible():
        await self.expansion_service.expand_to_object(obj)

    # Center view
    self.canvas.center_on(obj)
    self.selection_model.select(obj)
```

#### With E04 (Selection Model)
```python
# search_panel.py
def on_result_selected(self, result: SearchResult):
    # Navigator updates selection
    self.navigator.navigate_to(result.object_id)
    # Selection model emits signal
    # Canvas redraws with highlight
```

#### With E06 (Undo/Redo)
```python
# Future integration: Navigation operations should be undoable
class NavigateCommand(QUndoCommand):
    def __init__(self, from_state, to_state):
        self.from_state = from_state  # prev view + selection
        self.to_state = to_state      # new view + selection

    def undo(self):
        self.navigator.restore_state(self.from_state)

    def redo(self):
        self.navigator.restore_state(self.to_state)
```

---

## 4. Technical Deep Dive

### 4.1 Search Index Design

#### Data Structures
```python
@dataclass
class SearchIndex:
    """Pre-built index for O(1) name lookup"""

    # Primary maps: name -> object(s)
    cells: Dict[str, Cell]                    # Unique cell instance names
    nets: Dict[str, Net]                      # Unique net names
    ports: Dict[str, Port]                    # Unique port names
    pins: Dict[str, List[Pin]]                # Many pins share names (e.g., "A", "Q")

    # Reverse maps: object_id -> name (for quick lookup)
    id_to_name: Dict[str, str]

    # Metadata for performance
    total_objects: int
    build_time: float
    last_updated: datetime

    def add_objects(self, objects: List[GraphObject]):
        """Incrementally add objects (called during expansion)"""

    def remove_objects(self, object_ids: List[str]):
        """Remove objects (called during collapse)"""

    def search(self, pattern: re.Pattern, filters: SearchFilters) -> List[str]:
        """Return object IDs matching pattern and filters"""
```

#### Index Building Strategy
```python
class IndexBuilder:
    def build(self, graph: NetlistGraph) -> SearchIndex:
        """Build index from graph"""
        index = SearchIndex()

        # Single pass through graph
        for node_id, node_data in graph.nodes(data=True):
            obj_type = node_data['type']
            obj_name = node_data['name']

            if obj_type == 'cell':
                index.cells[obj_name] = node_data['object']
            elif obj_type == 'net':
                index.nets[obj_name] = node_data['object']
            elif obj_type == 'port':
                index.ports[obj_name] = node_data['object']
            elif obj_type == 'pin':
                index.pins.setdefault(obj_name, []).append(node_data['object'])

            index.id_to_name[node_id] = obj_name

        index.total_objects = len(index.id_to_name)
        return index
```

**Memory Analysis:**
```
Assumptions:
- 100K cells, 200K pins, 150K nets, 100 ports = 450K objects
- Average name length: 20 chars
- Python object overhead: 56 bytes per dict entry

Memory calculation:
- Names: 450K × 20 = 9MB
- Dict entries: 450K × 56 = 25MB
- Object references: 450K × 8 = 3.6MB (pointers)
- Total: ~38MB for 450K objects

Conclusion: Negligible compared to graph structure (easily 500MB+)
```

---

### 4.2 Pattern Matching Implementation

#### Wildcard to Regex Conversion
```python
import re
from typing import Optional

class PatternMatcher:
    """Converts user-friendly wildcards to compiled regex patterns"""

    # Cache compiled patterns to avoid recompilation
    _pattern_cache: Dict[str, re.Pattern] = {}

    @staticmethod
    def compile_pattern(query: str) -> re.Pattern:
        """Convert wildcard query to case-insensitive regex"""

        if query in PatternMatcher._pattern_cache:
            return PatternMatcher._pattern_cache[query]

        # Escape special regex chars
        escaped = re.escape(query)

        # Convert wildcards
        regex_str = escaped.replace(r'\*', '.*').replace(r'\?', '.')

        # Compile with case-insensitive flag
        pattern = re.compile(f'^{regex_str}$', re.IGNORECASE)

        # Cache for reuse
        PatternMatcher._pattern_cache[query] = pattern

        return pattern

    @staticmethod
    def validate_pattern(query: str) -> Optional[str]:
        """Validate query and return error message if invalid"""

        # Check for empty query
        if not query or len(query.strip()) < 2:
            return "Query must be at least 2 characters"

        # Check for invalid characters (if any)
        # Most chars are valid in object names, but we can restrict if needed

        # Try to compile to catch regex errors
        try:
            PatternMatcher.compile_pattern(query)
            return None  # Valid
        except re.error as e:
            return f"Invalid pattern: {str(e)}"
```

#### Search Algorithm
```python
class SearchEngine:
    def __init__(self, index: SearchIndex):
        self.index = index
        self.matcher = PatternMatcher()

    def search(self, query: str, filters: SearchFilters) -> List[SearchResult]:
        """Execute search and return ranked results"""

        # Validate query
        error = self.matcher.validate_pattern(query)
        if error:
            raise ValueError(error)

        # Compile pattern
        pattern = self.matcher.compile_pattern(query)

        # Collect matches
        results = []

        if filters.include_cells:
            results.extend(self._search_cells(pattern))
        if filters.include_nets:
            results.extend(self._search_nets(pattern))
        if filters.include_ports:
            results.extend(self._search_ports(pattern))
        if filters.include_pins:
            results.extend(self._search_pins(pattern))

        # Rank results (exact matches first)
        results = self._rank_results(results, query)

        # Limit results
        return results[:filters.max_results]

    def _search_cells(self, pattern: re.Pattern) -> List[SearchResult]:
        """Search cell names"""
        results = []
        for name, cell in self.index.cells.items():
            if pattern.match(name):
                results.append(SearchResult(
                    object_type='cell',
                    name=name,
                    object_id=cell.id,
                    context=f"Cell: {cell.cell_type}"
                ))
        return results

    def _rank_results(self, results: List[SearchResult], query: str) -> List[SearchResult]:
        """Rank results by relevance"""
        query_lower = query.lower().replace('*', '').replace('?', '')

        def rank_key(result: SearchResult):
            name_lower = result.name.lower()

            # Exact match (ignoring case) = highest priority
            if name_lower == query_lower:
                return (0, name_lower)

            # Starts with query = medium priority
            if name_lower.startswith(query_lower):
                return (1, name_lower)

            # Contains query = low priority
            return (2, name_lower)

        return sorted(results, key=rank_key)
```

**Performance Optimization:**
- Pattern compilation cached (first search: 10μs, subsequent: O(1))
- Single pass through each map (no nested loops)
- Early termination when `max_results` reached
- Ranking done only on filtered results (not entire dataset)

**Complexity Analysis:**
```
Let N = total objects, M = matching objects, K = max_results

Pattern compilation: O(1) with cache
Search: O(N) - single pass through all names
Ranking: O(M log M) - sort only matches
Limiting: O(K) - slice operation

Total: O(N + M log M)

For typical queries:
- N = 100K objects
- M = 100-1000 matches (1% match rate)
- K = 100 results

Time: 100K × 1μs + 1K × log(1K) × 1μs ≈ 100ms + 10ms = 110ms
Worst case (all match): 100K × log(100K) ≈ 1.7s (mitigated by max_results)
```

---

### 4.3 Debouncing for Real-Time Search

#### Problem
User typing triggers search on every keystroke. For query "clock_gate_123":
- 14 keystrokes = 14 searches
- Most searches incomplete ("c", "cl", "clo", ...)
- Wastes CPU and creates visual noise

#### Solution: Debounced Input
```python
from PySide6.QtCore import QTimer, Signal
from PySide6.QtWidgets import QLineEdit

class DebouncedLineEdit(QLineEdit):
    """Line edit that emits textChangedDebounced after delay"""

    textChangedDebounced = Signal(str)

    def __init__(self, debounce_ms: int = 250, parent=None):
        super().__init__(parent)

        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self._on_debounce_timeout)
        self.debounce_ms = debounce_ms

        # Connect to immediate signal
        self.textChanged.connect(self._on_text_changed)

    def _on_text_changed(self, text: str):
        """Restart timer on each keystroke"""
        self.debounce_timer.stop()
        self.debounce_timer.start(self.debounce_ms)

    def _on_debounce_timeout(self):
        """Emit debounced signal after delay"""
        self.textChangedDebounced.emit(self.text())
```

**Usage in SearchPanel:**
```python
class SearchPanel(QDockWidget):
    def __init__(self):
        self.search_input = DebouncedLineEdit(debounce_ms=250)
        self.search_input.textChangedDebounced.connect(self._execute_search)

    def _execute_search(self, query: str):
        """Only called 250ms after user stops typing"""
        if len(query) < 2:
            return  # Minimum query length

        results = self.search_service.search(query, self.get_filters())
        self._display_results(results)
```

**Debounce Timing Analysis:**
- 250ms: Sweet spot for responsiveness vs efficiency
- Too short (100ms): Still triggers many intermediate searches
- Too long (500ms+): Feels laggy to user
- Configurable in settings for user preference

---

### 4.4 Navigation Implementation

#### Auto-Expansion Strategy
```python
class Navigator:
    def __init__(self, graph, expansion_service, canvas, selection_model):
        self.graph = graph
        self.expansion_service = expansion_service
        self.canvas = canvas
        self.selection_model = selection_model

    async def navigate_to(self, object_id: str):
        """Navigate to object, expanding if necessary"""

        obj = self.graph.get_object(object_id)

        if obj is None:
            raise ValueError(f"Object not found: {object_id}")

        # Step 1: Ensure object is visible
        if not self._is_visible(obj):
            await self._expand_to_show(obj)

        # Step 2: Select object
        self.selection_model.clear()
        self.selection_model.select(obj)

        # Step 3: Pan view to center on object
        self._center_view_on(obj)

        # Step 4: Zoom to appropriate level
        self._zoom_to_fit(obj)

        # Step 5: Visual feedback (optional highlight/flash)
        self._flash_highlight(obj)

    def _is_visible(self, obj: GraphObject) -> bool:
        """Check if object is currently in expanded graph"""
        return obj.id in self.canvas.visible_objects

    async def _expand_to_show(self, obj: GraphObject):
        """Expand graph to make object visible"""

        # Strategy: Find shortest path from any visible object to target
        # Then expand along that path

        visible_ids = set(self.canvas.visible_objects.keys())

        # BFS to find shortest path
        path = self.graph.shortest_path_to_visible(obj.id, visible_ids)

        if not path:
            # Object is completely disconnected - expand entire component
            # This is rare but can happen in multi-module designs
            await self.expansion_service.expand_component(obj)
        else:
            # Expand along path
            for node_id in path:
                if node_id not in visible_ids:
                    await self.expansion_service.expand_node(node_id)

    def _center_view_on(self, obj: GraphObject):
        """Pan view to center on object"""
        obj_center = self.canvas.get_object_center(obj.id)
        viewport_center = self.canvas.viewport().rect().center()

        # Calculate offset
        delta = obj_center - viewport_center

        # Animate pan (smooth scroll)
        self.canvas.animate_pan(delta, duration_ms=150)

    def _zoom_to_fit(self, obj: GraphObject):
        """Zoom to appropriate level for object"""

        # Get object bounding box
        bbox = self.canvas.get_object_bbox(obj.id)

        # Calculate zoom to fit object + margin
        margin = 50  # pixels
        target_rect = bbox.adjusted(-margin, -margin, margin, margin)

        # Zoom to show target rect
        self.canvas.fit_in_view(target_rect, duration_ms=150)

    def _flash_highlight(self, obj: GraphObject):
        """Briefly flash object to draw attention"""
        # Implement using QPropertyAnimation on opacity
        # Flash yellow highlight for 500ms then fade
        pass
```

#### Performance Considerations
```python
# Optimization: Batch expansion operations
# Instead of: expand A, expand B, expand C (3 layout recalculations)
# Do: expand [A, B, C] (1 layout recalculation)

async def _expand_to_show(self, obj: GraphObject):
    path = self.graph.shortest_path_to_visible(obj.id, visible_ids)

    # Collect all nodes to expand
    to_expand = [n for n in path if n not in visible_ids]

    # Batch expand
    await self.expansion_service.expand_batch(to_expand)
```

---

### 4.5 Search History Management

#### Persistence Strategy
```python
import json
from pathlib import Path
from collections import deque

class SearchHistory:
    """Manages search query history with persistence"""

    def __init__(self, max_size: int = 10, storage_path: Optional[Path] = None):
        self.max_size = max_size
        self.storage_path = storage_path or Path.home() / '.ink' / 'search_history.json'
        self.queries: deque[str] = deque(maxlen=max_size)
        self._load()

    def add(self, query: str):
        """Add query to history (removes duplicates, keeps most recent)"""
        # Remove if already exists
        if query in self.queries:
            self.queries.remove(query)

        # Add to front
        self.queries.appendleft(query)

        # Persist
        self._save()

    def get_recent(self, limit: int = 10) -> List[str]:
        """Get recent queries"""
        return list(self.queries)[:limit]

    def clear(self):
        """Clear all history"""
        self.queries.clear()
        self._save()

    def _save(self):
        """Save to disk"""
        self.storage_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.storage_path, 'w') as f:
            json.dump(list(self.queries), f)

    def _load(self):
        """Load from disk"""
        if not self.storage_path.exists():
            return

        try:
            with open(self.storage_path, 'r') as f:
                queries = json.load(f)
                self.queries = deque(queries, maxlen=self.max_size)
        except (json.JSONDecodeError, IOError):
            # Corrupted file - start fresh
            self.queries = deque(maxlen=self.max_size)
```

**Integration with SearchPanel:**
```python
class SearchPanel(QDockWidget):
    def __init__(self):
        self.history = SearchHistory()
        self.history_dropdown = QComboBox()
        self.history_dropdown.addItems(self.history.get_recent())
        self.history_dropdown.activated.connect(self._on_history_selected)

    def _execute_search(self, query: str):
        results = self.search_service.search(query, self.get_filters())

        # Add to history only if search had results
        if results:
            self.history.add(query)
            self._update_history_dropdown()

        self._display_results(results)

    def _update_history_dropdown(self):
        self.history_dropdown.clear()
        self.history_dropdown.addItems(self.history.get_recent())
```

---

## 5. Risk Analysis

### 5.1 Technical Risks

#### Risk 1: Search Performance Degradation on Very Large Netlists
**Severity**: High
**Probability**: Medium
**Impact**: Search becomes unusable above 500K objects

**Mitigation Strategy:**
1. **Profiling**: Benchmark with 100K, 500K, 1M object netlists in testing
2. **Trie Optimization**: If hash map + regex exceeds 200ms, implement trie for prefix search
3. **Background Search**: Move search to background thread to prevent UI freeze
4. **Progressive Results**: Show first 100 results immediately, load more on scroll
5. **Index Sharding**: Partition index by object type for parallel search

**Contingency Plan:**
If performance remains poor:
- Implement incremental search (require 3+ chars before searching)
- Add "Search in Background" mode for complex patterns
- Limit search scope to visible objects by default (with "Search All" option)

**Monitoring:**
```python
import time

class SearchEngine:
    def search(self, query: str, filters: SearchFilters) -> List[SearchResult]:
        start = time.perf_counter()
        results = self._execute_search(query, filters)
        elapsed_ms = (time.perf_counter() - start) * 1000

        # Log slow searches
        if elapsed_ms > 200:
            logger.warning(f"Slow search: {query} took {elapsed_ms:.1f}ms")

        return results
```

---

#### Risk 2: Index Inconsistency After Expansion/Collapse
**Severity**: Medium
**Probability**: Medium
**Impact**: Search returns stale results or misses new objects

**Mitigation Strategy:**
1. **Explicit Index Updates**: Expansion service calls `index.add_objects()` after expansion
2. **Validation Checks**: Assert index size matches visible object count in dev mode
3. **Rebuild Trigger**: Provide manual "Rebuild Index" action in UI
4. **Incremental Validation**: Spot-check index entries during search

**Implementation:**
```python
class ExpansionService:
    async def expand_node(self, node_id: str):
        new_objects = self._expand_internal(node_id)

        # Update index
        self.search_index.add_objects(new_objects)

        # Validate in debug mode
        if __debug__:
            self._validate_index_consistency()

    def _validate_index_consistency(self):
        visible_count = len(self.graph.visible_nodes())
        index_count = self.search_index.total_objects

        if visible_count != index_count:
            logger.error(f"Index inconsistency: {visible_count} visible, {index_count} indexed")
```

---

#### Risk 3: Navigation Expansion Creates Infinite Loop
**Severity**: High
**Probability**: Low
**Impact**: Application hangs when navigating to certain objects

**Scenario:**
Object A references object B which references object A (circular dependency). Auto-expansion could loop forever.

**Mitigation Strategy:**
1. **Expansion Depth Limit**: Cap auto-expansion at N hops (default: 10)
2. **Visited Tracking**: Track expanded nodes to prevent re-expansion
3. **Timeout**: Abort expansion after T seconds (default: 5s)
4. **User Feedback**: Show "Expanding..." progress dialog with cancel button

**Implementation:**
```python
async def _expand_to_show(self, obj: GraphObject, max_depth: int = 10):
    """Expand to show object with depth limit"""

    visited = set()
    depth = 0

    while not self._is_visible(obj) and depth < max_depth:
        path = self.graph.shortest_path_to_visible(obj.id, visible_ids)

        if not path:
            raise NavigationError("Cannot reach object from visible graph")

        # Expand next node in path
        next_node = path[0]

        if next_node in visited:
            raise NavigationError("Circular expansion detected")

        visited.add(next_node)
        await self.expansion_service.expand_node(next_node)
        depth += 1

    if depth >= max_depth:
        raise NavigationError(f"Max expansion depth ({max_depth}) exceeded")
```

---

#### Risk 4: Regex Denial of Service (ReDoS)
**Severity**: Low
**Probability**: Low
**Impact**: Malicious or accidental pattern causes search hang

**Scenario:**
User enters pattern like `*a*a*a*a*a*` which compiles to regex `.*a.*a.*a.*a.*a.*`
On input like "aaaaaaaaaaaaaaaaaaaaaaaX", this causes catastrophic backtracking.

**Mitigation Strategy:**
1. **Pattern Complexity Limit**: Restrict number of wildcards (e.g., max 5 `*` chars)
2. **Timeout**: Use `re` module's timeout parameter (Python 3.11+) or regex library
3. **Whitelist Patterns**: Only allow simple wildcards, not arbitrary regex
4. **Alternative Engine**: Use `re2` library which guarantees linear time

**Implementation:**
```python
def compile_pattern(query: str) -> re.Pattern:
    """Compile with safety checks"""

    # Count wildcards
    wildcard_count = query.count('*') + query.count('?')
    if wildcard_count > 5:
        raise ValueError("Too many wildcards (max 5)")

    # Check for dangerous patterns (e.g., adjacent wildcards)
    if '**' in query or '*?*' in query:
        raise ValueError("Adjacent wildcards not allowed")

    # Compile with timeout (Python 3.11+)
    escaped = re.escape(query)
    regex_str = escaped.replace(r'\*', '.*').replace(r'\?', '.')

    try:
        return re.compile(f'^{regex_str}$', re.IGNORECASE)
    except re.error as e:
        raise ValueError(f"Invalid pattern: {e}")
```

---

### 5.2 User Experience Risks

#### Risk 5: Too Many Results Overwhelm User
**Severity**: Medium
**Probability**: High
**Impact**: User cannot find target in 1000+ result list

**Mitigation Strategy:**
1. **Result Limiting**: Cap at 100 results by default
2. **Overflow Message**: Show "Showing 100 of 1,247 results - refine query" message
3. **Smart Ranking**: Exact matches first, then prefix matches
4. **Progressive Disclosure**: "Load More" button for additional results
5. **Filter Suggestions**: Suggest enabling filters if too many results

**Implementation:**
```python
def _display_results(self, results: List[SearchResult]):
    self.results_list.clear()

    if len(results) == 0:
        self.results_list.addItem("No results found")
        return

    # Show first 100
    for result in results[:100]:
        item = self._create_result_item(result)
        self.results_list.addItem(item)

    # Show overflow message
    if len(results) > 100:
        overflow_item = QListWidgetItem(
            f"⚠ Showing 100 of {len(results)} results - refine query for better results"
        )
        overflow_item.setFlags(Qt.ItemIsEnabled)  # Not selectable
        overflow_item.setForeground(QColor('orange'))
        self.results_list.addItem(overflow_item)
```

---

#### Risk 6: Search Panel Blocks Critical Canvas Area
**Severity**: Low
**Probability**: Medium
**Impact**: User cannot see schematic while searching

**Mitigation Strategy:**
1. **Dockable Panel**: User can move/resize/undock panel
2. **Auto-Hide Option**: Panel auto-collapses after navigation
3. **Keyboard-Only Mode**: Allow search without opening panel (Ctrl+F → type → Enter → Esc)
4. **Transparency Option**: Semi-transparent panel overlay (P1 feature)

---

## 6. Testing Strategy

### 6.1 Unit Tests

#### Search Index Tests
```python
# tests/services/search/test_index.py

def test_index_build():
    """Index builds correctly from graph"""
    graph = create_test_graph(cells=100, nets=50, ports=10)
    index = SearchIndex.build(graph)

    assert index.total_objects == 160  # 100 cells + 50 nets + 10 ports
    assert len(index.cells) == 100
    assert len(index.nets) == 50

def test_index_add_objects():
    """Incremental add updates index"""
    index = SearchIndex()
    cell = Cell(id='C1', name='my_cell')

    index.add_objects([cell])

    assert 'my_cell' in index.cells
    assert index.total_objects == 1

def test_index_remove_objects():
    """Remove updates index"""
    index = create_index_with_objects()

    index.remove_objects(['C1'])

    assert 'C1' not in index.id_to_name
```

#### Pattern Matching Tests
```python
# tests/services/search/test_patterns.py

def test_exact_match():
    pattern = PatternMatcher.compile_pattern('clk')
    assert pattern.match('clk')
    assert pattern.match('CLK')  # case-insensitive
    assert not pattern.match('clk_gate')

def test_prefix_wildcard():
    pattern = PatternMatcher.compile_pattern('*_clk')
    assert pattern.match('sys_clk')
    assert pattern.match('core_clk')
    assert not pattern.match('clk_gate')

def test_suffix_wildcard():
    pattern = PatternMatcher.compile_pattern('clk_*')
    assert pattern.match('clk_gate')
    assert pattern.match('clk_div')
    assert not pattern.match('sys_clk')

def test_substring_wildcard():
    pattern = PatternMatcher.compile_pattern('*clk*')
    assert pattern.match('sys_clk_gate')
    assert pattern.match('my_clk')
    assert not pattern.match('data_bus')

def test_single_char_wildcard():
    pattern = PatternMatcher.compile_pattern('data_?')
    assert pattern.match('data_a')
    assert pattern.match('data_1')
    assert not pattern.match('data_ab')

def test_pattern_validation():
    error = PatternMatcher.validate_pattern('a')  # Too short
    assert error is not None

    error = PatternMatcher.validate_pattern('clk')
    assert error is None
```

#### Search Service Tests
```python
# tests/services/search/test_service.py

def test_search_with_filters():
    """Filters correctly exclude object types"""
    service = create_search_service()

    # Only cells
    filters = SearchFilters(include_nets=False, include_ports=False, include_pins=False)
    results = service.search('*', filters)

    assert all(r.object_type == 'cell' for r in results)

def test_result_ranking():
    """Exact matches ranked higher than partial"""
    service = create_search_service()
    results = service.search('clk', SearchFilters())

    # Result named exactly 'clk' should be first
    assert results[0].name.lower() == 'clk'

def test_result_limiting():
    """Results limited to max_results"""
    service = create_search_service()
    filters = SearchFilters(max_results=10)

    results = service.search('*', filters)  # Match everything

    assert len(results) <= 10

def test_search_performance():
    """Search completes within time budget"""
    service = create_search_service(object_count=10000)

    start = time.perf_counter()
    results = service.search('*clk*', SearchFilters())
    elapsed = time.perf_counter() - start

    assert elapsed < 0.2  # 200ms
```

---

### 6.2 Integration Tests

#### Search + Navigation Tests
```python
# tests/integration/test_search_navigation.py

@pytest.mark.asyncio
async def test_navigate_to_visible_object():
    """Navigation to visible object succeeds"""
    app = create_test_app()
    cell = app.graph.cells[0]

    await app.navigator.navigate_to(cell.id)

    assert app.selection_model.selected_object == cell
    assert app.canvas.is_centered_on(cell)

@pytest.mark.asyncio
async def test_navigate_to_hidden_object():
    """Navigation auto-expands hidden object"""
    app = create_test_app()
    hidden_cell = app.graph.get_hidden_cell()

    await app.navigator.navigate_to(hidden_cell.id)

    assert hidden_cell.is_visible()
    assert app.selection_model.selected_object == hidden_cell

@pytest.mark.asyncio
async def test_search_and_navigate():
    """End-to-end: search → select result → navigate"""
    app = create_test_app()

    # Search
    results = app.search_service.search('target_cell', SearchFilters())
    assert len(results) > 0

    # Navigate to first result
    await app.navigator.navigate_to(results[0].object_id)

    # Verify navigation
    assert app.canvas.is_visible(results[0].object_id)
    assert app.selection_model.is_selected(results[0].object_id)
```

#### Index Consistency Tests
```python
def test_index_updates_after_expansion():
    """Index stays consistent with graph after expansion"""
    app = create_test_app()
    initial_count = app.search_index.total_objects

    # Expand a node
    app.expansion_service.expand_node('cell_with_fanout')

    # Index should have more objects
    assert app.search_index.total_objects > initial_count

    # Search should find newly visible objects
    results = app.search_service.search('*', SearchFilters())
    assert len(results) == app.search_index.total_objects

def test_index_updates_after_collapse():
    """Index updates correctly after collapse"""
    app = create_test_app()
    app.expansion_service.expand_node('cell_1')
    expanded_count = app.search_index.total_objects

    # Collapse
    app.expansion_service.collapse_node('cell_1')

    # Index should shrink
    assert app.search_index.total_objects < expanded_count
```

---

### 6.3 UI Tests

#### Search Panel Tests
```python
# tests/ui/test_search_panel.py

def test_search_panel_opens_with_shortcut(qtbot):
    """Ctrl+F opens search panel"""
    window = create_main_window()
    qtbot.addWidget(window)

    # Press Ctrl+F
    qtbot.keyPress(window, Qt.Key_F, Qt.ControlModifier)

    # Panel should be visible
    assert window.search_panel.isVisible()
    assert window.search_panel.search_input.hasFocus()

def test_debounced_search(qtbot):
    """Search executes after debounce delay"""
    panel = create_search_panel()
    qtbot.addWidget(panel)

    search_executed = False
    def on_search():
        nonlocal search_executed
        search_executed = True

    panel.search_executed.connect(on_search)

    # Type query
    qtbot.keyClicks(panel.search_input, 'clk')

    # Should not execute immediately
    assert not search_executed

    # Wait for debounce
    qtbot.wait(300)

    # Should execute now
    assert search_executed

def test_result_selection_triggers_navigation(qtbot):
    """Clicking result triggers navigation"""
    panel = create_search_panel_with_results()
    qtbot.addWidget(panel)

    navigated_to = None
    def on_navigate(object_id):
        nonlocal navigated_to
        navigated_to = object_id

    panel.navigate_requested.connect(on_navigate)

    # Click first result
    panel.results_list.setCurrentRow(0)
    qtbot.mouseClick(panel.results_list.viewport(), Qt.LeftButton)

    assert navigated_to is not None
```

---

### 6.4 Performance Tests

```python
# tests/performance/test_search_performance.py

@pytest.mark.benchmark
def test_index_build_performance():
    """Index builds within time budget"""
    graph = create_large_graph(cells=100000, nets=200000)

    start = time.perf_counter()
    index = SearchIndex.build(graph)
    elapsed = time.perf_counter() - start

    print(f"Index build: {elapsed:.2f}s for {index.total_objects} objects")
    assert elapsed < 5.0  # 5 seconds max

@pytest.mark.benchmark
def test_search_performance_large_netlist():
    """Search performs well on large netlist"""
    service = create_search_service(object_count=100000)

    test_queries = [
        'exact_name',
        '*clk*',
        'prefix_*',
        '*_suffix',
        'a*b*c*',
    ]

    for query in test_queries:
        start = time.perf_counter()
        results = service.search(query, SearchFilters())
        elapsed = time.perf_counter() - start

        print(f"Query '{query}': {elapsed*1000:.1f}ms ({len(results)} results)")
        assert elapsed < 0.2  # 200ms max

@pytest.mark.benchmark
def test_incremental_index_update_performance():
    """Index updates quickly after expansion"""
    index = create_large_index(100000)
    new_objects = create_test_objects(100)  # Typical expansion size

    start = time.perf_counter()
    index.add_objects(new_objects)
    elapsed = time.perf_counter() - start

    print(f"Index update: {elapsed*1000:.1f}ms for {len(new_objects)} objects")
    assert elapsed < 0.01  # 10ms max
```

---

### 6.5 Test Data Strategy

#### Synthetic Netlists
Create test netlists with known patterns:

```python
def create_search_test_netlist():
    """Generate netlist with predictable naming for search tests"""

    netlist = Netlist()

    # Exact match test cases
    netlist.add_cell('clk', cell_type='BUF')
    netlist.add_cell('data', cell_type='BUF')

    # Prefix patterns
    for i in range(10):
        netlist.add_cell(f'clk_gate_{i}', cell_type='AND2')
        netlist.add_cell(f'data_reg_{i}', cell_type='DFF')

    # Suffix patterns
    for i in range(10):
        netlist.add_cell(f'{i}_clk', cell_type='BUF')

    # Substring patterns
    netlist.add_cell('my_clk_divider', cell_type='DIV')
    netlist.add_cell('core_clk_gen', cell_type='CLK_GEN')

    # Edge cases
    netlist.add_cell('', cell_type='BUF')  # Empty name
    netlist.add_cell('a', cell_type='BUF')  # Single char
    netlist.add_cell('a' * 1000, cell_type='BUF')  # Very long name

    return netlist
```

#### Real-World Samples
Include anonymized production netlists:

```
examples/netlists/search_tests/
├── small_10k.ckt        # 10K objects
├── medium_100k.ckt      # 100K objects
├── large_500k.ckt       # 500K objects
└── patterns.ckt         # Specific pattern test cases
```

---

### 6.6 Test Coverage Goals

**Target Coverage:**
- **Line Coverage**: >90%
- **Branch Coverage**: >85%
- **Critical Path Coverage**: 100% (search, navigate, index update)

**Coverage by Component:**
```
Component                    Target
────────────────────────────────────
SearchIndex                   95%
PatternMatcher               100%
SearchService                 90%
Navigator                     85%
SearchPanel                   80%
```

**Uncovered Code (Acceptable):**
- Error handling for truly exceptional cases (disk full, OOM)
- Defensive assertions that should never trigger
- Legacy compatibility code
- Debug/logging code

---

## 7. Definition of Done

### 7.1 Feature Completeness

#### Core Functionality
- [ ] Search panel opens with Ctrl+F and focuses input
- [ ] Search executes on Enter or after 250ms debounce delay
- [ ] Wildcard patterns `*` and `?` work correctly
- [ ] Results display within 100ms for 10K+ objects
- [ ] Results limited to 100 with overflow message
- [ ] Filters (Cells/Pins/Nets/Ports) correctly exclude object types
- [ ] Case-insensitive matching enabled by default
- [ ] Search history stores last 10 queries
- [ ] History dropdown allows re-executing past searches
- [ ] Clear history button works

#### Navigation
- [ ] Clicking result selects object in canvas
- [ ] View pans to center on selected object within 200ms
- [ ] View zooms to appropriate level for object
- [ ] Hidden objects auto-expand before navigation
- [ ] Selection highlight visible after navigation
- [ ] Navigation works for all object types (cells, pins, nets, ports)

#### Edge Cases
- [ ] Empty query shows no results (not error)
- [ ] Query <2 chars shows "Type at least 2 characters" message
- [ ] Invalid pattern shows error message
- [ ] No results shows "No results found" message
- [ ] Search panel closes with Esc key
- [ ] Search works with empty/minimal netlist

---

### 7.2 Code Quality

#### Implementation Standards
- [ ] All classes have docstrings
- [ ] All public methods have type hints
- [ ] Complex logic has inline comments
- [ ] No TODO/FIXME comments in committed code
- [ ] Code passes `mypy` type checking with no errors
- [ ] Code passes `ruff` linting with no errors
- [ ] PEP 8 compliance (100 char line limit)

#### Architecture
- [ ] Clear separation: UI / Service / Data layers
- [ ] SearchIndex decoupled from UI
- [ ] SearchService coordinates between components
- [ ] Navigator integrates with existing expansion/selection services
- [ ] No circular dependencies

---

### 7.3 Testing

#### Test Coverage
- [ ] Unit tests for SearchIndex (build, add, remove, search)
- [ ] Unit tests for PatternMatcher (all wildcard cases)
- [ ] Unit tests for SearchService (filters, ranking, limiting)
- [ ] Integration tests for search + navigation
- [ ] Integration tests for index consistency
- [ ] UI tests for SearchPanel interactions
- [ ] Performance tests for 100K object netlist
- [ ] All tests pass in CI

#### Test Quality
- [ ] Test coverage >90% (measured by pytest-cov)
- [ ] No flaky tests (100% pass rate over 10 runs)
- [ ] Performance tests document benchmarks
- [ ] Tests run in <30 seconds total

---

### 7.4 Documentation

#### User Documentation
- [ ] Search panel usage documented in user guide
- [ ] Wildcard pattern syntax documented with examples
- [ ] Keyboard shortcuts listed in help menu
- [ ] Search history behavior explained

#### Developer Documentation
- [ ] Architecture diagram in this pre-docs
- [ ] API documentation for SearchService
- [ ] Integration guide for other components
- [ ] Performance benchmarks documented

#### Code Documentation
- [ ] All public classes have docstrings
- [ ] Complex algorithms have explanatory comments
- [ ] Type hints on all function signatures
- [ ] Examples in docstrings for key methods

---

### 7.5 Performance

#### Benchmarks
- [ ] Index build: <5s for 100K objects
- [ ] Search latency: <100ms for 10K+ objects
- [ ] Navigation latency: <200ms including expansion
- [ ] Index update: <10ms for 100-object expansion
- [ ] Memory overhead: <10% of graph size

#### Scalability
- [ ] Tested with 100K object netlist
- [ ] Tested with 500K object netlist (performance documented)
- [ ] No memory leaks (valgrind or similar)
- [ ] No performance degradation after repeated searches

---

### 7.6 User Experience

#### Usability
- [ ] Search feels responsive (<100ms perceived latency)
- [ ] Results are relevant (exact matches first)
- [ ] Navigation animations smooth (no jank)
- [ ] Error messages are clear and actionable
- [ ] Keyboard workflow works without mouse

#### Polish
- [ ] Loading indicators for >200ms operations
- [ ] Visual feedback on navigation (highlight flash)
- [ ] Search panel state persists across sessions
- [ ] Icons for object types in results list
- [ ] Tooltips on filter buttons

---

### 7.7 Integration

#### Dependencies Verified
- [ ] E01 (Data Model) provides object names
- [ ] E03 (Expansion) supports auto-expansion for navigation
- [ ] E04 (Selection) updates correctly on navigation
- [ ] Main window integrates search panel

#### Compatibility
- [ ] Works with all supported netlist formats
- [ ] Compatible with existing undo/redo (future work)
- [ ] Search panel docking doesn't break other panels

---

### 7.8 Deployment

#### Release Readiness
- [ ] Feature flag available for gradual rollout
- [ ] No breaking changes to existing APIs
- [ ] Migration path for old search (if any)
- [ ] Release notes written

#### Monitoring
- [ ] Search performance logged (slow queries >200ms)
- [ ] Index build time logged
- [ ] Error rates tracked
- [ ] User engagement metrics (searches per session)

---

## 8. Appendix

### 8.1 Alternative Approaches Considered

#### Alternative 1: Full-Text Search with SQLite FTS
**Description**: Use SQLite's FTS5 for full-text search capabilities.

**Pros:**
- Mature, battle-tested search engine
- Advanced features (phrase search, ranking, highlighting)
- Persistent storage built-in

**Cons:**
- Overhead of SQL queries
- Additional dependency (SQLite lib)
- Overkill for simple name matching
- Harder to integrate with in-memory graph

**Decision**: Rejected for MVP. Consider for P1 if advanced features needed.

---

#### Alternative 2: Elasticsearch for Search
**Description**: Use Elasticsearch as external search engine.

**Pros:**
- Industrial-grade search
- Scalable to massive datasets
- Advanced analytics

**Cons:**
- Massive dependency (JVM, separate service)
- Requires network communication
- Far too heavyweight for desktop app
- Complexity doesn't match problem scale

**Decision**: Rejected. Not appropriate for desktop tool.

---

#### Alternative 3: Autocomplete with Trie
**Description**: Build trie for prefix-based autocomplete as user types.

**Pros:**
- Great UX (real-time suggestions)
- Fast prefix search O(k) where k = query length
- Familiar pattern from IDEs

**Cons:**
- More complex than hash map
- Memory overhead for trie structure
- Doesn't help with suffix/substring patterns

**Decision**: Defer to P1. MVP uses simpler hash map + regex. Add trie if profiling shows need.

---

### 8.2 Performance Benchmarking Plan

#### Benchmark Suite
```python
# benchmarks/search_benchmark.py

class SearchBenchmark:
    """Comprehensive search performance tests"""

    def bench_index_build(self):
        """Measure index build time across netlist sizes"""
        for size in [1000, 10000, 50000, 100000, 500000]:
            graph = create_graph(size)

            start = time.perf_counter()
            index = SearchIndex.build(graph)
            elapsed = time.perf_counter() - start

            print(f"{size:>6} objects: {elapsed:>6.2f}s")

    def bench_search_patterns(self):
        """Measure search time for different pattern types"""
        service = create_service(100000)

        patterns = {
            'exact': 'clk_gate_1234',
            'prefix': 'clk_*',
            'suffix': '*_gate',
            'substring': '*clk*',
            'complex': 'a*b*c*d*',
        }

        for name, pattern in patterns.items():
            times = []
            for _ in range(100):
                start = time.perf_counter()
                service.search(pattern, SearchFilters())
                elapsed = time.perf_counter() - start
                times.append(elapsed)

            avg = statistics.mean(times)
            p95 = statistics.quantiles(times, n=20)[18]

            print(f"{name:>10}: avg={avg*1000:.1f}ms p95={p95*1000:.1f}ms")
```

**Target Results:**
```
Index Build:
  1,000 objects:   0.01s
 10,000 objects:   0.10s
 50,000 objects:   0.50s
100,000 objects:   1.00s
500,000 objects:   5.00s

Search Patterns (100K objects):
     exact: avg=0.5ms   p95=1.0ms
    prefix: avg=20ms    p95=30ms
    suffix: avg=50ms    p95=80ms
 substring: avg=80ms    p95=120ms
   complex: avg=100ms   p95=150ms
```

---

### 8.3 Keyboard Shortcuts Reference

| Shortcut | Action |
|----------|--------|
| Ctrl+F | Open search panel |
| Esc | Close search panel |
| Enter | Execute search / Navigate to selected result |
| Ctrl+G | Find next result |
| Ctrl+Shift+G | Find previous result |
| Up/Down | Navigate results list |
| Ctrl+H | Open search history |
| Ctrl+Shift+F | Search with options dialog |

---

### 8.4 Future Enhancements (Post-MVP)

#### P1 Features
1. **Trie-based Autocomplete**
   - Real-time suggestions as user types
   - Show top 5 matches in dropdown
   - Navigate with arrow keys

2. **Regular Expression Mode**
   - Toggle for advanced users
   - Full regex syntax support
   - Syntax highlighting in input

3. **Search Scopes**
   - Visible objects only
   - Specific hierarchy level
   - Selected region

4. **Search Result Export**
   - Copy results to clipboard
   - Export to CSV
   - Save search as "smart group"

5. **Search Performance Visualization**
   - Show search time in status bar
   - Highlight performance bottlenecks
   - Suggest pattern optimizations

#### P2 Features
1. **Semantic Search**
   - "Find all flip-flops in clock domain X"
   - "Show critical path from A to B"
   - Natural language queries

2. **Search Result Annotations**
   - Add notes to frequently searched objects
   - Tag search results
   - Color-code result categories

3. **Multi-Object Navigation**
   - Navigate to multiple results simultaneously
   - Highlight all matches in canvas
   - Cycle through matches with F3/Shift+F3

4. **Search Analytics**
   - Most searched objects
   - Common search patterns
   - Search efficiency metrics

---

### 8.5 Cross-References

**Related Specifications:**
- E01 (Data Model): Object naming and ID system
- E03 (Expansion): Auto-expansion for navigation
- E04 (Selection): Selection state management
- E06 (Undo/Redo): Future integration for navigation undo

**Related Documentation:**
- PRD §8: Search and Navigation requirements
- User Guide: Search panel usage
- API Docs: SearchService interface

---

## Revision History

| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-12-26 | 1.0 | Claude | Initial pre-docs creation |

---

**Document Status**: Ready for Review
**Next Steps**: Review → Approve → Begin Phase 1 Implementation
**Estimated Implementation Time**: 3 weeks (1 engineer)
