---
id: E01-F01-T01
title: CDL Lexer and Tokenizer
type: Task
priority: P0 (MVP)
status: Draft
parent: E01-F01
created: 2025-12-26
estimated_hours: 4-6
actual_hours:
effort: Small
tags:
  - parsing
  - infrastructure
  - foundation
---

# Spec: E01-F01-T01 - CDL Lexer and Tokenizer

## 1. Overview

### 1.1 Problem Statement
CDL files contain various line types (subcircuit definitions, instances, comments, blank lines) that need to be classified and cleaned before detailed parsing. Line continuation with `+` must be handled, and comment stripping is required. A robust lexer provides the foundation for higher-level parsing.

### 1.2 Goals
- Implement line-level tokenization and classification
- Handle line continuation with `+` prefix
- Strip comments starting with `*`
- Classify lines by type (SUBCKT, ENDS, INSTANCE, COMMENT, BLANK)
- Provide clean, normalized lines to downstream parsers
- Report line numbers for error tracking

---

## 2. Technical Requirements

### 2.1 Implementation Details

**Location**: `src/ink/infrastructure/parsing/cdl_lexer.py`

**Core Classes**:
```python
from enum import Enum
from dataclasses import dataclass
from typing import List, Iterator
from pathlib import Path

class LineType(Enum):
    """CDL line types"""
    SUBCKT = "SUBCKT"      # .SUBCKT definition
    ENDS = "ENDS"          # .ENDS terminator
    INSTANCE = "INSTANCE"  # X-prefixed instance
    TRANSISTOR = "TRANSISTOR"  # M-prefixed transistor
    COMMENT = "COMMENT"    # * comment line
    BLANK = "BLANK"        # Empty or whitespace-only
    UNKNOWN = "UNKNOWN"    # Unrecognized format

@dataclass
class CDLToken:
    """A tokenized CDL line"""
    line_num: int          # Original line number (1-indexed)
    line_type: LineType    # Classified type
    content: str           # Cleaned content (comments stripped, continuation joined)
    raw: str               # Original raw line

class CDLLexer:
    """Lexical analyzer for CDL files"""

    def __init__(self, file_path: Path):
        self.file_path = file_path

    def tokenize(self) -> Iterator[CDLToken]:
        """Yield tokens from CDL file, handling continuation and comments"""
        pass

    def _classify_line(self, content: str) -> LineType:
        """Classify line by type based on content"""
        pass

    def _strip_comment(self, line: str) -> str:
        """Remove inline comments starting with *"""
        pass

    def _handle_continuation(self, lines: List[str]) -> str:
        """Join lines with + continuation prefix"""
        pass
```

### 2.2 API/Interface

**Public Interface**:
```python
# Usage example
lexer = CDLLexer(Path("design.ckt"))
for token in lexer.tokenize():
    if token.line_type == LineType.SUBCKT:
        # Process subcircuit definition
        pass
    elif token.line_type == LineType.INSTANCE:
        # Process instance
        pass
```

**Token Output**:
- Each token represents one logical line (after continuation joining)
- Line numbers track original file position
- Content is cleaned (whitespace normalized, comments removed)
- Raw preserves original for error reporting

### 2.3 Testing Requirements

**Unit Tests** (`tests/unit/infrastructure/parsing/test_cdl_lexer.py`):
```python
def test_classify_subckt_line():
    """Test .SUBCKT line classification"""
    assert lexer._classify_line(".SUBCKT INV A Y") == LineType.SUBCKT

def test_classify_instance_line():
    """Test X-prefixed instance classification"""
    assert lexer._classify_line("XI1 net1 net2 INV") == LineType.INSTANCE

def test_strip_inline_comment():
    """Test inline comment removal"""
    assert lexer._strip_comment("XI1 A Y INV * comment") == "XI1 A Y INV"

def test_handle_continuation():
    """Test multi-line continuation with +"""
    lines = ["XI1 net1 net2", "+ net3 net4 INV"]
    assert lexer._handle_continuation(lines) == "XI1 net1 net2 net3 net4 INV"

def test_tokenize_sample_file():
    """Test tokenization of sample CDL file"""
    # Create temp file with known content
    # Verify correct tokens generated
```

**Edge Cases**:
- Empty files
- Files with only comments
- Multiple consecutive blank lines
- Lines with only whitespace
- Comments at end of instance lines
- Multiple levels of continuation
- CRLF vs LF line endings
- Very long continued lines (>10 continuation lines)

---

## 3. Dependencies
- **Upstream**: None (reads raw files from filesystem)
- **Downstream**:
  - E01-F01-T02 (Subcircuit Parser) - consumes SUBCKT/ENDS tokens
  - E01-F01-T03 (Instance Parser) - consumes INSTANCE tokens

---

## 4. Acceptance Criteria
- [ ] `CDLLexer` class correctly classifies all line types (SUBCKT, ENDS, INSTANCE, COMMENT, BLANK)
- [ ] Inline comments starting with `*` are stripped from content
- [ ] Line continuation with `+` prefix correctly joins multi-line statements
- [ ] Original line numbers are preserved in tokens for error reporting
- [ ] Iterator-based API yields tokens lazily for memory efficiency
- [ ] Handles CRLF and LF line endings
- [ ] Skips M-prefixed transistor lines (classified as TRANSISTOR)
- [ ] 95%+ test coverage with all edge cases covered
- [ ] Successfully tokenizes sample CDL file from PRD Appendix A

---

## Revision History
| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-12-26 | 0.1 | Claude | Initial task creation from E01-F01 split |
