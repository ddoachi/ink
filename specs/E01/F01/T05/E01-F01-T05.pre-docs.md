# Pre-Implementation Documentation: E01-F01-T05 - CDL Parser Integration

## Overview

### Problem Context
The individual parsing components (lexer, subcircuit parser, instance parser, net normalizer) need to be orchestrated into a unified workflow that produces a complete `Design` aggregate root. This integration layer is responsible for:

**Workflow Orchestration**: Coordinating the parsing pipeline in correct order
**Error Management**: Collecting errors/warnings from all components with line numbers
**Progress Reporting**: Providing feedback for UI during long-running parses
**Domain Model Construction**: Assembling parsed data into `Design` aggregate
**Performance Optimization**: Meeting 100K cells in <5 seconds requirement

This is the public API for CDL parsing - the interface that application layer services will use.

### Goals
Build a robust integration layer that handles all error conditions gracefully, provides detailed error reporting, and meets performance requirements for large designs.

---

## Implementation Approach

### High-Level Strategy

**Architecture Pattern**: Facade pattern with two-pass parsing

**Processing Flow**:
```
Parse File
    ↓
Pass 1: Tokenize + Parse Subcircuits
    ↓
Validate All Subcircuits Closed
    ↓
Pass 2: Parse Instances (with subcircuit defs)
    ↓
Build Design Aggregate
    ↓
Validate + Report Errors
```

### Algorithm Design

**Two-Pass Strategy**:

**Why Two Passes?**
- Instances reference subcircuit definitions
- Need all definitions available before parsing instances
- Allows forward references (instance before subcircuit definition in file)

**Pass 1: Collect Subcircuit Definitions**
```python
tokens = list(lexer.tokenize())  # Materialize for two passes

subckt_parser = SubcircuitParser()
for token in tokens:
    if token.line_type == LineType.SUBCKT:
        try:
            subckt_parser.parse_subckt_line(token)
        except ValueError as e:
            self._add_error(token.line_num, str(e), "error")
    elif token.line_type == LineType.ENDS:
        try:
            subckt_parser.parse_ends_line(token)
        except ValueError as e:
            self._add_error(token.line_num, str(e), "error")

subckt_parser.validate_complete()  # Check all blocks closed
```

**Pass 2: Parse Instances**
```python
instance_parser = InstanceParser(subckt_parser._definitions)

for token in tokens:
    if token.line_type == LineType.INSTANCE:
        try:
            instance = instance_parser.parse_instance_line(token)
            instances.append(instance)
        except ValueError as e:
            self._add_error(token.line_num, str(e), "error")
            # Continue parsing (partial load)

# Collect warnings
for warning in instance_parser.get_warnings():
    self._add_error(-1, warning, "warning")
```

**Design Construction**:
```python
def _build_design(...) -> Design:
    # Collect unique nets from all instances
    nets = {}
    for instance in instances:
        for port, net_name in instance.connections.items():
            if net_name not in nets:
                nets[net_name] = net_normalizer.normalize(net_name)

    # Build instance map
    instance_map = {inst.name: inst for inst in instances}

    # Create Design aggregate
    return Design(
        name=name,
        subcircuit_defs=subcircuit_defs,
        instances=instance_map,
        nets=nets
    )
```

### Data Structures

```python
@dataclass
class ParsingError:
    line_num: int          # -1 if not line-specific
    message: str
    severity: str          # "error" or "warning"

class CDLParser:
    _errors: List[ParsingError]
    _progress_callback: Optional[Callable[[int, int], None]]

@dataclass
class Design:
    name: str
    subcircuit_defs: Dict[str, SubcircuitDefinition]
    instances: Dict[str, CellInstance]
    nets: Dict[str, NetInfo]
    top_level_ports: List[str]  # Future: parse from top SUBCKT
```

---

## Key Design Decisions

### Decision 1: Two-Pass vs Single-Pass Parsing

**Options**:
- A) Two-pass: (1) subcircuits, (2) instances
- B) Single-pass: Interleaved parsing with deferred resolution
- C) Multi-pass: (1) tokenize, (2) subcircuits, (3) instances

**Recommendation**: Option A (Two-pass)

**Rationale**:
- Simpler implementation - clear separation of concerns
- Handles forward references naturally
- Token list fits in memory for realistic designs (100K lines ≈ 10MB)
- Performance acceptable (tokenization is fast)

**Trade-off**: Doubles iteration over tokens, but simplifies logic

### Decision 2: Error Handling Strategy

**Options**:
- A) Fail fast - halt on first error
- B) Collect all errors - continue parsing
- C) Hybrid - halt on critical errors, continue on warnings

**Recommendation**: Option C (Hybrid)

**Rationale**:
- Provides best user experience (see all errors at once)
- Supports partial loading (show what could be parsed)
- Distinguishes critical vs. non-critical issues

**Critical Errors** (halt parsing):
- Unclosed subcircuit blocks
- File not found / unreadable
- Corrupt file structure

**Non-Critical Errors** (continue parsing):
- Unknown cell types
- Connection count mismatches
- Duplicate instance names (skip duplicate, warn)

### Decision 3: Progress Reporting Mechanism

**Options**:
- A) No progress reporting
- B) Line number callback
- C) Percentage callback
- D) Stage-based callback (tokenizing, pass 1, pass 2)

**Recommendation**: Option B (Line number callback)

**Rationale**:
- Simple interface: `callback(current_line, total_lines)`
- UI can compute percentage
- Granular enough for responsive feedback
- Low overhead (check every N lines)

**Implementation**:
```python
if self._progress_callback and i % 100 == 0:
    self._progress_callback(i, total_lines)
```

**Throttling**: Update every 100 lines to avoid callback overhead

### Decision 4: Design Aggregate Ownership

**Options**:
- A) Parser owns Design, provides getters
- B) Parser returns Design, caller owns
- C) Parser populates caller-provided Design

**Recommendation**: Option B (Return Design)

**Rationale**:
- Clean separation - parser is transient, Design persists
- Natural Python API (factory pattern)
- Parser can be garbage collected after parsing

**Lifecycle**:
```python
parser = CDLParser()           # Create parser
design = parser.parse_file()   # Parse and return Design
# parser goes out of scope
# design is used by application layer
```

### Decision 5: Top-Level Port Detection

**Options**:
- A) Detect from first `.SUBCKT` in file
- B) Require explicit top-level marker
- C) Detect from instances not instantiated elsewhere
- D) Skip for MVP (empty list)

**Recommendation**: Option D (Skip for MVP)

**Rationale**:
- Not required for MVP features (expand/collapse)
- Can be added in future without breaking changes
- Complexity not justified for initial implementation

**Future Enhancement**: Option A (first subcircuit = top-level)

---

## Dependencies and Integration Points

### Upstream Dependencies

**All Parsing Components**:
- E01-F01-T01 (CDL Lexer) - Tokenization
- E01-F01-T02 (Subcircuit Parser) - Subcircuit definitions
- E01-F01-T03 (Instance Parser) - Cell instances
- E01-F01-T04 (Net Normalizer) - Net classification

**Required Imports**:
```python
from pathlib import Path
from .cdl_lexer import CDLLexer, LineType
from .subcircuit_parser import SubcircuitParser
from .instance_parser import InstanceParser
from .net_normalizer import NetNormalizer
from ..domain.model.design import Design
```

### Downstream Consumers

**E01-F03 (Graph Construction)**:
- Uses `Design` aggregate to build NetworkX graph
- Accesses `design.instances` and `design.nets`

**E02-F01 (File Load Service)**:
- Application layer service wrapping parser
- Handles UI error display
- Manages progress bar updates

### Interface Contract

**Public API**:
```python
def parse_file(
    file_path: Path,
    progress_callback: Optional[Callable[[int, int], None]] = None
) -> Design:
    """Parse CDL file and return Design aggregate

    Args:
        file_path: Path to .ckt file
        progress_callback: Optional callback(current_line, total_lines)

    Returns:
        Design aggregate root

    Raises:
        ValueError: If file cannot be parsed (critical errors)
        FileNotFoundError: If file doesn't exist
    """
```

**Error Retrieval**:
```python
def get_errors(self) -> List[ParsingError]:
    """Return all parsing errors and warnings"""
```

---

## Testing Strategy

### Integration Test Coverage

**End-to-End Success Cases**:
1. `test_parse_simple_design` - Minimal working CDL
2. `test_parse_hierarchical_design` - Nested subcircuits
3. `test_parse_bus_notation` - Bus nets normalized
4. `test_parse_power_ground_nets` - Special nets classified

**Error Handling**:
5. `test_parse_with_warnings` - Unknown cell types (partial load)
6. `test_parse_with_recoverable_errors` - Connection mismatches
7. `test_parse_with_critical_errors` - Unclosed subcircuit (fail)
8. `test_parse_duplicate_instance_names` - Error reported

**Progress Reporting**:
9. `test_progress_callback_invoked` - Callback called during parse
10. `test_progress_callback_parameters` - Correct line counts passed

**Performance**:
11. `test_performance_100k_cells` - Parse 100K instances in <5s
12. `test_memory_usage_large_design` - Memory efficient

**Edge Cases**:
13. `test_parse_empty_file` - Graceful handling
14. `test_parse_only_comments` - No design returned
15. `test_parse_file_not_found` - FileNotFoundError
16. `test_parse_very_large_file` - 1M+ lines

### Test Data Strategy

**Fixture Files** (in `tests/fixtures/cdl/`):
```
simple.ckt           - Minimal working design (INV chain)
hierarchical.ckt     - Nested subcircuits
bus_notation.ckt     - Bus nets and arrays
power_ground.ckt     - Various power/ground nets
errors_unclosed.ckt  - Missing .ENDS
errors_unknown.ckt   - Unknown cell types
large_10k.ckt        - 10K instances (generated)
large_100k.ckt       - 100K instances (generated)
```

**Fixture Generation**:
```python
def generate_large_cdl(num_instances: int) -> str:
    """Generate CDL file with N instances for testing"""
    lines = [".SUBCKT INV A Y VDD VSS", ".ENDS INV", ""]
    for i in range(num_instances):
        lines.append(f"XI{i} net{i} net{i+1} VDD VSS INV")
    return "\n".join(lines)
```

### Performance Testing

**Benchmark Setup**:
```python
def test_performance_100k_cells(tmp_path, benchmark):
    # Generate 100K instance file
    cdl_content = generate_large_cdl(100_000)
    cdl_file = tmp_path / "large.ckt"
    cdl_file.write_text(cdl_content)

    parser = CDLParser()

    # Benchmark
    import time
    start = time.time()
    design = parser.parse_file(cdl_file)
    elapsed = time.time() - start

    # Assertions
    assert elapsed < 5.0, f"Parsing took {elapsed:.2f}s, expected <5s"
    assert len(design.instances) == 100_000
    assert len(design.subcircuit_defs) == 1
```

**Profiling** (if performance issues):
```python
import cProfile
cProfile.run('parser.parse_file(cdl_file)', 'parse_stats.prof')
# Analyze with snakeviz or pstats
```

---

## Risks and Considerations

### Risk 1: Memory Usage with Large Files
**Likelihood**: Medium
**Impact**: Medium

**Description**: Materializing all tokens into list for two-pass parsing could use significant memory

**Mitigation**:
- Benchmark memory usage with 1M line file
- If needed, optimize: Stream tokens, build subcircuit map, then re-tokenize for instances
- For MVP: Accept memory trade-off for simpler code

**Threshold**: If >1GB memory for 1M lines, optimize

### Risk 2: Performance Bottleneck in Net Collection
**Likelihood**: Low
**Impact**: Medium

**Description**: Building net dictionary by iterating all instance connections could be slow

**Mitigation**:
- Use dict for O(1) lookups
- Net normalizer caching reduces overhead
- Profile if performance issues arise

### Risk 3: Partial Loading Correctness
**Likelihood**: Medium
**Impact**: High

**Description**: Continuing after errors could produce invalid connectivity graph

**Mitigation**:
- Clear error messages indicating partial load
- Validate Design aggregate before returning
- Add "is_complete" flag to Design if needed

**Validation**:
```python
def validate_design(design: Design) -> List[str]:
    """Check Design integrity, return issues"""
    issues = []
    for inst in design.instances.values():
        if inst.cell_type not in design.subcircuit_defs:
            issues.append(f"Instance {inst.name} references unknown type {inst.cell_type}")
    return issues
```

### Risk 4: Progress Callback Overhead
**Likelihood**: Low
**Impact**: Low

**Description**: Frequent callback invocations could slow parsing

**Mitigation**:
- Update every 100 lines (not every line)
- Callback is optional (None check is fast)
- Benchmark with and without callbacks

### Risk 5: File Encoding Issues
**Likelihood**: Medium
**Impact**: Medium

**Description**: CDL files may have non-UTF8 encoding

**Mitigation**:
- Open with `encoding='utf-8', errors='ignore'`
- Log warning if decode errors occur
- Document supported encodings

**Implementation**:
```python
try:
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
except UnicodeDecodeError:
    raise ValueError(f"File {file_path} has unsupported encoding")
```

### Implementation Complexity
**Overall**: Medium

**Rationale**:
- Orchestration of multiple components
- Error handling logic is complex
- Performance optimization required
- Good test coverage essential

### Integration Challenges
**Level**: Medium

**Considerations**:
- Depends on all other parsing components (must complete first)
- Domain model (Design) must be well-designed
- Error reporting must be comprehensive

---

## Success Metrics

### Functional Requirements
- [ ] Parse PRD sample file (Appendix A) successfully
- [ ] Return complete Design aggregate with all instances
- [ ] Collect all errors with line numbers
- [ ] Progress callback invoked during parse

### Non-Functional Requirements
- [ ] Parse 100K instances in <5 seconds
- [ ] Memory usage <500MB for 1M line file
- [ ] 90%+ integration test coverage

### Quality Gates
- [ ] All integration tests pass
- [ ] Performance benchmark meets target
- [ ] Type checking passes (mypy strict)
- [ ] Error messages clear and actionable

---

## Implementation Checklist

### Phase 1: Domain Model (1 hour)
- [ ] Update `src/ink/domain/model/design.py`
- [ ] Implement `Design` aggregate root
- [ ] Add instance/net/subcircuit collections
- [ ] Add helper methods (add_instance, get_instance, etc.)
- [ ] Write domain model tests

### Phase 2: Integration Core (2-3 hours)
- [ ] Create `src/ink/infrastructure/parsing/cdl_parser.py`
- [ ] Implement `ParsingError` dataclass
- [ ] Implement `CDLParser.__init__`
- [ ] Implement `parse_file` method with two-pass logic
- [ ] Implement `_build_design` method
- [ ] Add error collection and formatting
- [ ] Add progress callback support

### Phase 3: Testing (2-2.5 hours)
- [ ] Create test fixtures (simple, hierarchical, errors)
- [ ] Write end-to-end integration tests
- [ ] Write error handling tests
- [ ] Write progress callback test
- [ ] Generate large files for performance testing
- [ ] Write performance benchmark

### Phase 4: Validation (0.5-1 hour)
- [ ] Run full integration test suite
- [ ] Performance profiling
- [ ] Memory profiling
- [ ] Type checking
- [ ] Linting
- [ ] Documentation review

**Total Estimated Time**: 5-6 hours (matches spec estimate)

---

## Future Enhancements

### Post-MVP Features
1. **Top-Level Port Detection**: Auto-detect design I/O from first subcircuit
2. **Incremental Parsing**: Parse only changed sections for file watching
3. **Multi-File Support**: Parse libraries across multiple CDL files
4. **Schema Validation**: Formal validation of Design aggregate
5. **Export to JSON**: Serialize Design for caching

### Performance Optimizations
1. **Streaming Parse**: Avoid materializing token list (one-pass with forward refs)
2. **Parallel Parsing**: Parse independent subcircuits in parallel
3. **Binary Cache**: Cache parsed Design as pickle for fast reload
